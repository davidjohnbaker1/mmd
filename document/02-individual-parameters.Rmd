## Individual Differences

The first two steps of Gary Karpinki's model of melodic dictation [@karpinskiAuralSkillsAcquisition2000; @karpinskiModelMusicPerception1990] rely exclusivly on the mental representation of melodic information.
Karpinski conceptualizes the first stage of _hearing_ as soley involving the physical motions on the tympanic membrane as well as each lister's attention to the musical stimulus.
This stage is distinguished from that of _short-term melodic memory_ which refers to the amount of melodic information that can be represented in memory.
Given that neither stage of the first two steps of Karpinki's model requires any sort of musical expertise, every individual with normal hearing should be able to partake in the first two steps of the process.^[This whole model needs critique under the WMC literature. It's kind of strange to think that the act of something hitting your ear is different than attention (the way that Cowan thinks about WMC and again that you can split up the represenation in memory from that of what the characteritics are of the melody like the meter and scale degrees, which have been argued to be part of intrinsic qualia) also there is a big problem here about stuff being activly rehearsed or not]


Karpinski limits the amount of melodic information that can enter _short-term melodic memory_ "somwhere between five and nine notes", citing Miller [@millerMagicalNumberSeven1956] then supports 

Via the process of Extractive Listening and Chunking are individuals then further able to "extend the capacity of short-term melodic memory"



these are all skills that most people can have 


I. establish musical memory is key component in melodic dictation
- not super specific (is it rehearsed, active, baddely vs cowan)
- logic here is presumed that as people get better at MD then able to do more
- quote from karinski to support that
- ALso there is anecdotal evidence to support that bc people get better at MD
- could be that people are getting better musical memory
- but also that they could be getting better at chunking
- IMPORTANTLY this rests on premise that ability in increasing due to training effects
- But what is the baseline?
- And what is the direction of causality 
- And aside from training, are there other cognitive abilities that contribe to this?

II. Berz and WM 
- THis point is made by Berz who addressed the issue and noted that he thought WMC 
- Berz notes that althoguht many musical aptitude tests purport to measure aptitude could be WM.
- Could it be that these are reflecting differences in cognitive ability?

This chapter seeks to understand how much baseline cognitive play into these kinds of ideas


In order for an individual to be able to complete a melodic dictation, they must be able to remember the melody that they are trying to dictate.
Using the Karpinski model, this would be the in the first two steps.

How does this relate to melodic dictation
Need to be able to hear a melody (step 2 of Karpinski)
Presumed that musical training leads to this increase in melody (talamini)
Where the idea is that as you get better with music, can chunk more efficently.
Even langauge to suggest that people are improving their melodic memory.
This is still under assumption that musical training leads to increaes in musical abiliyt

of course not going to doubt that training works, but need to question the assumptions of this. 


But according to GS and OS, could be that the causality is the other way around.
If this is the case, instead of measuring muscial memory, could just have overly domain specific measures of a general congitive function. 

A large amount of music psychology tests require some sort of musical memory.
Tasks range from same different to new old paradigms.
Idea is that you can predcit some of them with other things.

As pointed out by Berz (1995), 


## Literature Review

### Hook

Academic interest in the relationship between musical and cognitive ability dates back over a century.
In 1904, Charles Spearman [@spearmanGeneralIntelligenceObjectively1904] reported that Carl Seashore's pitch discrimination test (Seashore) correlated with his conception of general intelligence (.70, p.276), yet used an extensive footnote to highlight that there were "many notable instances will easily be found where musical ability is apparently divorced from General Intelligence"(p 275) suggesting that the relationship between music and cognitive ability is perhaps more complex than he originally reports.
He thought that it could be accounted for with......
But accounting for the last 100 years of research in this area demonstrates that great progress actually has been made in attempting to understand the relationship between music and cognitive ability. 
-- straight into polymorphism of ability


### Music and Cognitive Ability 

-- is this really just better to be about music and cognitive ability
-- or should i just straight out of the gate say that trying to emasure musicianship is miguided
-- really going to commit to the polymorphic view of musicianship
-- straight out of the gate 




The relationship between musical and cognitive ability is one the most active research topics in music psychology.
Owing much of the interest to the since debunked (CITE) excitement of far transfer claims from the Mozart Effect (CITE), more recent literature concerning the relationship between musical and cognitive ability focuses on looking at cross sectional studies.
- studies here. 

Okada and Slevc (XXXX) summerize the current state of the literature noting that


Overall main picture is that it could be one of three things.
Supported by literature that says XYZ. 


Though this is not just correlational evidence, in order to parse out causal there are rct.


Evidence is mixed here.
For example both GS and OS point out the lack of covariates.



People tend to frame the important studying of the link between two as possible way to improve cognition, thus improve quality.
Note here that this tethering is danger zone IMO bc first devalues music as cultural, second if connection goes based funding so do the arts. 


- national attention via Mozart Effect
- largely debunked
- correlational studies 
- given nature of studies 
- but to largely summerize, it is bascially at point with OS where there are three different possibliites. 
- 123
- get around this problem with many types of RCTs
- but many still do not take into account the many confounds in these types of tests
- Need studies that account for these measures

- Not only that, but field suffers from non-standard way to measure musicality
- and question of what is your dependant varaible of what is being measured
- relationshp exists, but depends how you conceptulize it.
- One way to get aroudn musicality problem is Gold-MSI
- points on gold msi 
- gives us standard measure of musicality, ontological problem
- also gives standard set of objective measrues
- people establish that there is something here.
- but one problem is that maybe that there more domain general processes accounting for this
- one way that other people have looked at it os OS
- They think about it as LV with three separate sets they define as xyz
- thing is, this is very close to WM (what they call separate)

- 


Two appear to be related and need to disentangle that relationship.
In general, appears they are linked and OS narrow it down to three posibilities. 
GS also selecition bias.

While many of the studies above establish that a relationship exists between current conceptualizations of musical abibility and cognitive ability, at play has yet to be agreed upon.
@okadaIndividualDifferencesMusical2018 

Problems with measurement! 

Cognitive
Established there is a relationship
Tho depends how you do it
One way of thinking about it via objective tests.
Melodic memory tests are like this 
And importantly like wmc
allows for way to look at things without confound of transcription

There is a lot of literature on it
The big problem is teasing out the directionality.
Okada and Slevc break it down with three possibility.
GS notes that it really could be that its selection bias.

Thing is that way OS set up EF, say it's three tasks.
Note these three tasks are basically how Cowan operatinlizes WM.

While they note there is literature that suggests each of these can be improved.
For example, n-back task.
And also note that most people won't do it.
Whole point is that this is probably tapping into other resources
Also does not give a complete picture of the full mechanism. 

So having done it as compartmentalized thing, theory guide the battery.
Now better to think about if model interfaces with world better when you conceptualize it as cowan WMC.
Specific to this chapter, want to know how general cognitive functions and training interface with AS.
Like OS, we too are interested in the Gold-MSI for reasons XYZ and taking LV approach.
Unlike OS, interested in specifically looking at how operational def of established cognitive things fx AS.

Plan to do this with first having proxy measure of AS.
This is the objective part of the gold-msi.
Has beat and melody.
Since improved. 
With the melodic task, you have to do this...
... bc of that we assume that this is tapping into same resources used in AS.
Like Berz said, basically WMC task.
But the good thing about this is that it also avoids the expertise problem.
Generally in the same camp, but note it is not a one-to-one mapping of the problem.

In order to better understand what predicts this, I present a series of SEMs.
Want to do some model building to see which set of measures best predicts WMC.
First IV is the Gold-MSI.
As noted it is robust tool for measuring musical sophisticaiton.
It has been replicated, tranlsated.
Also critiqued in that while helpful as LV, could have item level predictors to lifiting.

But in addition to musical sophistcation, could be domain general features.
In order to see if this is the case, need to investigate two important cognitive meaures.
The first is general fluid intelligence second is WMC.

Gf intelligence is ability to solve problems in novel situations.
Comes from contrast of Gc.
Generally solved with matrix reasoning tests.
And also bears statistical and theoretical simlarity to _g_.
Rationale was that since g is very predictive of many things (LIST) could be predictive here.
Doing GMSI melodic is a sort of problem solving.

WMC on other hand is defined as COWAN.
If conceptulaized like this, as compositie of WMC where you have to do all three of OS.
Then idea is that best measured with a complex span tasks.
This stands in contrast to much of the other WMC and music stuff (Koelsch).
Works within the baddely model of WMC which is this.
But thing is you can't always get exact material with loop
So Berz suggested a musical loop.
And literature has even been interpreted in that framework such as
Choose not to work within this framework bc how do you decide what gets loops.
Unlike much of other music psychology work that uses simple span
We use complex becaues the measure needs to be in line with the theoretical operationalization. 

Given a robust instrument for measuring musciality, and two well established cognive measrues as specifically defined, this study analysis seeks to investigate the degree to which these individual level variables are predictive of a task that is proxy to AS.

If much of musical memory has to do with Training, GMSI related variables should be most predictive.
If instead cognitive factors do play a role, should see that in path loadings.
Things could additionally interact and could do more complicated analyses with music level.

EVENTUALLY PUT ON THE IDYOM OF BERKOWITZ AND SEE IF THAT IS PREDICTIVE. 


# Individual Differences

Audience: Individuals familiar with cognitive science that would think music is good way to talk about cognitive abilites

Eventually i will say that 
* WMC is really governing a lot of this work and people need to control for this pre-existing difference
* 
## Introduction

hile musical ability is perhaps more affected by training than the other measures that were of interest to Spearman (i.e. language and mathematics), the relationship between musical and cognitive ability, and the factors that mediate their relationship still has yet to be fully understood.

* Current state suggests that in some cases, musicians tend to do better than non musical peers
* Okada and Slevc see this as explained by three possible hypotheses

1. Music makes you smarter
2. Smarter People take music lessons
3. Higher functioning people tend to take music lessons and music training amplifys already pre-existing differences.

It's important to get at this issue because if there were any causal elements found, this would have big implications since enhancing cognitive abilities would bring along with it the other benefits like X Y Z
While this might be a nice side fiding, important to note that even if a causal link were to be established, tethering music engagement to its ability to make someone smarter is a bad idea for numerous reasons probably given by schellenberg. 

Really the interesting reason to look into this relationship is that music, unlike other stimuli, provides a unique insight into looking things like gf and wmc bc no semantic information
For example, if what is more likley the third hypothesis is true and there are just pre-existing differences that do not change but are mabye amplified with music lessons, this would have serious implications for a lot of the findings in the music psychology literature. 


## Overview of Experiment (cross sectional design)

### Participants

Two hundred fifty-four students enrolled at Louisiana State University completed the study. 
We recruited students, mainly in the Department of Psychology and the School of Music.
The criteria for inclusion in the analysis were no self-reported hearing loss, not actively taking medication that would alter cognitive performance, and univariate outliers (defined as individuals whose performance on any task was greater than 3 standard deviations from the mean score of that task). 
Using these criteria, eight participants were not eligible due to self reporting hearing loss, one participant was removed for age, and six participants were eliminated as univariate outliers due to performance on one or more of the tasks of working memory capacity.
Thus, 239 participants met the criteria for inclusion. The eligible participants were between the ages of 17 and 43 (M = 19.72, SD = 2.74; 148 females). 
Participants volunteered, received course credit, or were paid $20.

### Materials

Cognitive Measures

All variables used for modeling approximated normal distributions. 
Processing errors for each task were positively skewed for the complex span tasks similar to Unsworth, Redick, Heitz, Broadway, and Engle (2009). 
Positive and significant correlations were found between recall scores on the three tasks measuring working memory capacity (WMC) and the two measuring general fluid intelligence (Gf). 
The WMC recall scores negatively correlated with the reported number of errors in each task, suggesting that rehearsal processes were effectively limited by the processing tasks (Unsworth et al., 2009).

#### Measures

##### Goldsmiths Musical Sophistication Index Self Report (Gold-MSI)

Participants completed a 38-item self-report inventory and questions consisted of free response answers or choosing a
selection on a likert scale that ranged from 1-7. (Müllensiefen, et al., 2014). 
The complete survey with all questions used can be found at goo.gl/dqtSaB.

##### Tone Span (TSPAN)

Participants completed a two-step math operation and then tried to remember three different tones in an alternating sequence (based upon Unsworth et al., 2005). 
We modelled the three tones after Li, Cowan, Saults (2005) paper using frequencies outside of the equal tempered system (200Hz, 375Hz, 702Hz). 
The same math operation procedure as OSPAN was used. The tones was presented aurally for 1000ms after each math operation. During tone recall, participants were presented three different options H M and L (High, Medium, and Low), each with its own check box.
Tones were recalled in serial order by clicking on each tone’s box in the appropriate order.
Tone recall was untimed.
Participants were provided practice trials and similar to OSPAN, the test procedure included three trials of each list length (3-7 tones), totalling 75 letters and 75 math operations.

##### Operation Span (OSPAN)

Participants completed a two-step math operation and then tried to remember a letter (F, H, J, K, L, N, P, Q, R, S, T, or
Y) in an alternating sequence (Unsworth et al., 2005). 
The same math operation procedure as TSPAN was used. 
The letter was presented visually for 1000ms after each math
operation. 
During letter recall, participants saw a 4 x 3 matrix of all possible letters, each with its own check box. 
Letters were recalled in serial order by clicking on each letter’s box in the appropriate order. 
Letter recall was untimed. 
Participants were provided practice trials and similar to TSPAN, the test procedure included three trials of each list length (3-7 letters), totalling 75 letters and 75 math operations.

##### Symmetry Span (SSPAN)

Participants completed a two-step symmetry judgment and were prompted to recall a visually-presented red square on a 4 X 4 matrix (Unsworth et al., 2005). 
In the symmetry judgment, participants were shown an 8 x 8 matrix with random squares filled in black. 
Participants had to decide if the black squares were symmetrical about the matrix’s vertical axis and then click the screen. 
Next, they were shown a “yes” and “no” box and clicked on the appropriate box. 
Participants then saw a 4 X 4 matrix for 650 ms with one red square after each symmetry judgment. 
During square recall, participants recalled the location of each red square by clicking on the appropriate cell in serial order. 
Participants were provided practice trials to become familiar with the procedure. 
The test procedure included three trials of each list length (2-5 red squares), totalling 42 squares and 42 symmetry judgments.

##### Gold-MSI Beat Perception

Participants were presented 18 excerpts of instrumental music from rock, jazz, and classical genres (Müllensiefen et
al., 2014). 
Each excerpt was presented for 10 to 16s through headphones and had a tempo ranging from 86 to 165 beats per
minute. 
A metronomic beep was played over each excerpt either on or off the beat. 
Half of the excerpts had a beep on the beat, and the other half had a beep off the beat. 
After each excerpt was played, participants answered if the metronomic beep was on or off the beat and provided their confidence: “I
am sure”, “I am somewhat sure”, or “I am guessing”. 
The final score was the proportion of correct responses on the beat judgment.

##### Gold-MSI Melodic Memory Test

Participants were presented melodies between 10 to 17 notes long through headphones (Müllensiefen et al., 2014).
There were 12 trials, half with the same melody and half with different melodies. 
During each trial, two versions of a melody were presented. 
The second version was transposed to a different key. 
In half of the second version melodies, a note was changed a step up or down from its original position in the structure of the melody. 
After each trial, participants answered if the two melodies had identical pitch interval structures.

##### Number Series

Participants were presented with a series of numbers with
an underlying pattern. 
After being given two example problems to solve, participants had 4.5 minutes in order to solve 15 different problems. 
Each trial had 5 different options as possible answers (Thurstone, 1938).

##### Raven’s Advanced Progressive Matrices

Participants were presented a 3 x 3 matrix of geometric patterns with one pattern missing (Raven et al., 1998). 
Up to eight pattern choices were given at the bottom of the screen. 
Participants had to click the choice that correctly fit the pattern above. 
There were three blocks of 12 problems, totalling 36 problems. 
The items increased in difficulty across each block. 
A maximum of 5 min was allotted for each block, totalling 15 min. 
The final score was the total number of correct responses across the three blocks.

### Procedure

Participants in this experiment completed eight different tasks, lasting about 90 minutes in duration. 
The tasks consisted of the Gold-MSI self-report inventory, coupled with the Short Test of Musical Preferences, and a supplementary demographic questionnaire that included questions about socioeconomic status, aural skills history, hearing loss, and any medication that might affect their ability to perform on cognitive tests. 
Following the survey they completed three WMC tasks: a novel Tonal Span, Symmetry span, and Operation span task; a battery of perceptual tests from the Gold-MSI (Melodic Memory, Beat Perception, Sound Similarity) and two tests of general fluid intelligence (Gf): Number Series and Raven’s Advanced Progressive Matrices.

Each task was administered in the order listed above on a desktop computer. 
Sounds were presented at a comfortable listening level for the tasks that required headphones. 
All participants provided informed consent and were debriefed.
Only measures used in modeling are reported below.

### Results

#### Descriptive, Data Screening, Correlational

The goal of the analyses was to examine the relationships among the measures and constructs of WMC, general fluid intelligence, musical sophistication (operationalized as the General score from the Gold-MSI), in relation to the two objective listening tests on the Gold-MSI. 
Before running any sort of modeling, we inspected our data to ensure in addition to outlier issues as mentioned above, the data exhibited normal distributions. 
We report both our correlation values, as well as visually displaying our distributions in Figure 1.

Before running any modeling, we checked our data for assumptions of normality since violations of normality can strongly affect the covariances between items. 
While some items in Figure 1 displayed a negative skew, many of the individual level items from the self report scale exhibited high
levels of Skew and Kurtosis beyond the generally accepted ± 2 (Field, Miles, & Field, 2012), but none of the items with the unsatisfactory measures are used in the general factor.

#### Modeling

##### Measurement Model

We then fit a measurement model to examine the underlying structure of the variables of interest used to assess the latent constructs (general musical sophistication, WMC, general fluid intelligence) by performing a confirmatory factor analysis (CFA) using the lavaan package (Rosseel, 2013) using R (R Core Team, 2017). 
Model fits in can be found in Table 3. 
For each model, latent factors were constrained to have a mean of 0 and variance of 1 in order to allow the latent covariances to be interpreted as correlations. 
Since the objective measures were on different scales, all variables were converted to z scores before running any modeling.

* MODEL HERE 

Variables are defined as follows: gen: general factor latent variable; wmc: working memory capacity; gf: general fluid intelligence; zIS: “Identify What is Special”; zHO: “Hear Once Sing Back”; zSB: “Sing Back After 2-3”; zDS: “Don’t Sing In Public”; zSH: “Sing In Harmony”; zJI:”Join In”; zNI: “Number of Instrumetns”; zRP:”Regular Practice”; zNCS: “Not Consider Self Musician”; zNcV: “Never Complimented”; zST: “Self Tonal”; zCP: “Compare Performances”; zAd: “Addiction”; zSI: “Search Internet”; zWr: “Writing About Music”; zFr: “Free Time”; zTP: “Tone Span”; zMS: “Symmetry Span”; zMO: “Operation Span”; zRA: “Ravens”; zAN: “Number Series”.

#### Structural Equation Models

Following the initial measurement model, we then fit a series of SEMs in order to investigate both the degree to which factor loadings changed when variables were removed from the model as well as the model fits. 
We began with a model incorporating our three latent variables (general musical sophistication, WMC, general fluid intelligence) predicting our two objective measures (beat perception and melodic memory scores) and then detailed steps we took in order to improve model fit. 
For each model, we calculated four model fits: χ2 , comparative fit index (CFI), root mean square error (RMSEA), and Tucker Lewis Index (TLI). 
In general, a non-significant χ2 indicates good model fit, but is overly sensitive to sample size. 
Comparative Fit Index (CFI) values of .95 or higher are considered to be indicative of good model fits as well as Root Mean Square Error (RMSEA) values of .06 or lower, Tucker Lewis Index (TLI) values closer to 1 indicate a better fit. (Beajean, 2014).

After running the first model (Model 1), we then examined the residuals between the correlation matrix the model expects and our actual correlation matrix looking for residuals
above .1. 
While some variables scored near .1, two items dealing with being able to sing (“I can hear a melody once and sing it back after hearing it 2 – 3 times” and “I can hear a melody once and sing it back”) exhibited a high level of correlation amongst the residuals (.41) and were removed for  Model 2 and model fit improved significantly (χ2 (41)=123.39,
p < . 001). 

After removing the poorly fitting items, we then proceeded to examine if removing the general musical sophistication self-report measures would significantly improve model fit for Model 3. 
Fit measures for Model 3 can be seen in Table 3 and removing the self-report items resulted in a significantly better model fit (χ2 (171)=438.8, p < . 001). 
Following the rule of thumb that at least 3 variables should be used to define any latent-variable (Beajuean, 2014) we modelled WMC as latent variable and Gf as a composite average of the two tasks administered in order to improve model fit. 
This model resulted in significant improvement to the model (χ2 (4)=14.37, p < . 001). 
Finally we examined the change in test statistics between Model 2 and a model that removed the cognitive measures-- a model akin to one of the original models reported in Müllensiefen et al., (2014)-- for Model 5. 
Testing between the two models resulted in a significant improvement in model fit (χ2 (78)=104.75, p < . 001). 
Figure 3 displays Model 4, our nested model with the best fit indices.

* TABLE HERE

* ALL FIGURES OF MODELS 

### Discussion

##### Measurement Model 

After running a confirmatory factor analysis on the variables of interest, the model fit was below the threshold of what is considered a “good model fit” as shown in Table 1 with references to above model fits. 
This finding is to be expected since no clear theoretical model has been put forward that would suggest that the general musical sophistication score, when modelled with two cognitive measures should have a good model fit. 
This model was run to create a baseline measurement.

##### Structural Equation Model Fitting

Following a series of nested model fits, we were able to improve model fits on a series of SEMs that incorporated both measures of WMC and measures of general fluid intelligence.
Before commenting on new models, it is worth noting that the Model 5 does not seem to align with the findings from the original 2014 paper by Müllensiefen et al. 
While the correlation between the objective tasks is the same (r = .16), the factor loadings from this paper suggest lower values for both Beat Perception (.37 original, .27 this paper) as well as Melodic Memory (.28 original, .18 this paper). 
Note that two items were removed dealing with melody for memory for this model; when those items were re-run with the data, the factor
loadings did not deviate from these numbers.

The first two models we ran resulted in minor improvements to model fit. 
While difference in models was significant (χ2 (41)=123.39, p < . 001 ), probably due to the
number of parameters that were now not constrained, the
relative fit indices of the models did not change drastically. 
It was not until the self-report measures were removed from the model, and then manipulated according to latent variable modeling recommendations, was there a marked increase in the relative fit indices. 
Fitting the model with only the cognitive measures, we were able to enter the bounds of acceptable relative fit indices that were noted above. 
In order to find evidence that the cognitive models (Models 3 and 4) were indeed a better fit than using the General factor, we additionally ran a comparison between our adjusted measurement model and a model with only the self report.
While both of our nested models were significantly different, the cognitive models exhibited superior relative fit indices.
Lastly, turning to Figure 3, we note that our latent variable of WMC exhibited much larger factor loadings predicting the two objective, perceptual tests than our measure of general fluid intelligence. 
We also note that the factor loading predicting the Beat Perception task (.36) was higher than that of the Melodic Memory task (.21). These rankings mirror that of the original Müllensiefen et al., (2014) paper and merit further examination in order to disentangle what processes are contributing to both tasks.

These results align with predictions made with Process Overlap Theory (Kovacs & Conway,
2016), which predict that higher executive loads are needed
for tasks of perception. 
While we failed to predict which task would load higher --we assumed that the ability to maintain and manipulate information in the Melodic Memory task would be better predicted by WMC than the Beat Perception task-- this might be due to the fact that performing well in a melodic memory task demands a certain amount of musical training that is not captured by either cognitive measure.
In the future, we are interested in exploring more theoretically-driven models that use specific, task oriented predictors in order to explain the relationships between the perceptual tasks and the cognitive measures. 
Given the results here that suggest that measures of cognitive ability play a significant role in tasks of musical perception, we suggest that future research should consider taking measures of cognitive ability into account, so that other variables of interest are able to be shown to contribute above and beyond baseline cognitive measures.

In this paper we fit a series of structural equation models in order to investigate the degree to which baseline cognitive ability was able to predict performance on a musical perception task. 
Our findings suggest that measures of WMC are able to account for a large amount of variance beyond that of self report in tasks of musical perception.
