# Hello, Corpus{#chapterfour}

## Rationale 

One of the essential features of any scientific discovery is the ability to reproduce the finding.
Given a new claim about reality, in order to be able to demonstrate that the claim is true, the new phenomena should remain invariant when reproduced.
If the phenomena satisfies pre-established criteria for causality, this evidence can be used to corroborate its generating theories.
This type of rationale is often associated with scientific methodologies, but music and science have a long, enjoyed history.
As noted by scholars like Allen Forte, "In virtually any historic period one finds an interaction between music and science and mathematics." [@forteMusicComputingPresent1967].
Music was one of the seven liberal arts during Roman times belonging to the quadrivium along with astronomy, geometry, and arithmetic.
In fact, many disciplinary differences in musical study more likely to result from geopolitical divides as how scholars conceptualize the study of music based on their location, rather than the content and form of their research [@parncuttSystematicMusicologyHistory2007].
It should then come as no surprise that studies in music will often interface with diverse methodologies. 

Returning to a phenomenon's invariance under different conditions, one of the most effective ways to investigate claims about the state of reality is to reproduce previously made claims using new data.
One of the most important contributions that a researcher can make towards either bolstering or refuting claims about the nature of music and its resulting theories would be to generate more materials in which to examine previous claims under new conditions.
In order to accomplish this, in this chapter I introduce a new corpus of sight-singing melodies based on the pedagogical text "A New Approach to Sight Singing" [@berkowitzNewApproachSight2011].
The corpus contains 783 monophonic melodies that have been digitally encoded in the kern format [@huronHumdrumToolkitReference1994] and contain both melodies specifically composed for use in the Aural Skills classroom and examples of melodies from outside musical literature.
Due to the fact that the corpus contains melodic data from a sight-singing anthology, for easier reference I will refer to it as the _MeloSol_ corpus.
After introducing the corpus, I compare the Melosol corpus with the Essen Folk Song collection [@schaffrathEssenFolkSong1995]  in order to highlight variability between these musical corpora.
I end by highlighting important considerations in the underlying representations of what the data represent and what these assumptions entail for future work in computational musicology. 

## History

The use of computers to study music has been been ongoing for over the past fifty years.
As reviewed by @hewlettComputingMusicology1991, early approaches to using music to study computers begin in the mid 1960s and due to the high effort and cost of computation, projects pursued by researchers at this time tended to focus on questions that might have global relevance.
The use of computers to study music at this time was not by any means a sparse area of study and throughout the second half of the 20th century, research in computational musicology grew in relation to the computing abilities afforded by the available technologies [@nettheimBibliographyStatisticalApplications1997].
During this time, not only was there progress made on computing power, many forms of developing new encoding frameworks were developed. 
As discussed by @wigginsFrameworkEvaluationMusic1993, the design and development of these encoding frameworks has impact on the degree that the systems can be assesed.
According to Wiggins and colleagues a framework can be evaluated on the two orthogonal dimensions of expressive completeness and structural generality. 
Considering what system is used to then encode musical information then becomes paramount given that the level of granularity that musical data is encoded will determine the types of questions that could eventually be asked in a computational analysis.
For example, data encoded in a MIDI or CHARM format is able to store micro-time variations in performance practice, which might lend it to being able to do performance based analyses on this data.
If this data were instead to have been encoded in just using a frequency spectrum as would be stored in an MP3 or WAV file, this type of analysis could not be carried out as accurately due to the task of automating the detection of pitch onsets.

On a higher level of abstraction, this problem of how a melody is encoded becomes exacerbated when considering meta-research issues such as the the tools-to-theories heuristic put forward by Gigerenzer [@gigerenzerToolsTheoriesHeuristic1991].
Gigerenzer claims that much of both the novelty and authority given to the trajectory of a research path is determined by the tools a group decided is valid, and not the generation of new data or theories.
Contextualizing this problem for digital music encoding, again choosing how to represent the data reflects ontological and epistemological assumptions about the data itself.
Further, the technology used to be able to query or test this data would provide an additional constraint on the analysis.

Currently there is a large amount of variability in types of encoding availble as well as tools that can be used for computer based analysis. 
Popular analysis software such as music21 [@cuthbertMusic21ToolkitComputerAided2010], David Huron's Humdrum [@huronHumdrumToolkitReference1994], as well as technologies being developed by the Single Interface for Music Score Searching and Analysis (SIMSSA) project based in McGill all exist as options for the musicologist to adopt.
Despite differences the advantages between both types of encoding and tools use to analyze this data, parsers such as the MeloSpySuite are constantly being developed to serve as digital music's Rosetta stone resulting in a current eco-system that allows for moving between options granted a competent degree of computer programming experience [@frielerIntroducingJazzomatProject2013]. 

While many of the encoding formats throughout the past 50 years have fallen out of favor, the kern format of encoding data developed by David Huron has persisted as a choice for many computational musicologists since its initial development in 1994.
The kern format (often stylized as ```**kern```) was developed in tandem with the Humdrum Toolbox for music analysis that according to Humdrum user guide is

> a set of command-line tools that facilitates musical analysis, as well as a generalized syntax for representing sequential streams of data. Because it’s a set of command-line tools, it’s program-language agnostic. Many have employed Humdrum tools in larger scripts that use PERL, Ruby, Python, Bash, LISP, and C++.

Humdrum files, unlike that of anything used in MEI are human readable and non-hierarchical, thus mirroring Western notated music's sequential time based nature.
Because of this, editing kern files using the humdrum tool set and humdrum extras developed by Craig Sapp [@sappHumdrumExtras2008] can be done with short, UNIX scripts as opposed to similar analyses in music21. 
Since moving between digitally encoded ecosystems is not nearly as difficult and much of encoding is can be left to the jurisdiction of the researcher, I have chose to encode this data set using the kern format. 

## Berkowitz Corpus

In this next section I introduce a new corpus of melodies encoded in the kern format.
The melodies come from the 5th edition of "A New Approach to Sight Singing" written by Sol Berkowitz, Gabriel Fontrier, Leo Kraft, Perry Goldstein, and Edward Smaldone, [@berkowitzNewApproachSight2011]. 
This corpus includes 783 melodies from the first and last chapters of the book.
The first chapter contains melodies from five different sections and the fifth chapter contains "Melodies from the Literature" and is made up of four sections.
Melodies from the first chapter have all been specifically composed for use in a sight-singing contexts.
Melodies from the fifth chapter are small excerpts from examples of both excerpts from Western Classical Music canon and traditional folksongs of various countries.
Some excerpts from the literature have been slightly modified for singablilty.

The information for each melody is recorded in the meta-data of the kern file. 
In addition to having a key signature in each kern file, I have also added an explicit key to each kern file.
Each section of the book contains melodies that would be considered tonal, except for melodies in the fifth section of the first chapter and intermittent melodies in the fourth section of the fifth chapter which contain atonal melodies.
If a melody is decidedly atonal or modal, this is documented in the metadata.
Atonal melodies are given the explicit key of C major so that they can be analyzed and parsed as if they were part of a fixed do system.



Panel XXX shows basic descriptive statistcs of the corpus showing statistics including the variation of length of the melodies, the distribution of keys, the range of melodies found in the corpus.
In comparison to other corpora, such as the canonical Essen folksong data base, the Berkowtiz has less melodies, but melodies are typically LONGER, reflects more diversity of keys, and does not reflect music of a particular national culture.
Contrasting the XXXXX tokens in the corpus, the Essen folk song ha XXXXXXX tokens. 

## Comparison of Corpora 

In order to gives brief overview of the corpus and contextualize it in the context of other corpora, in the next section I compare the Berkowtiz corpus to that of the Essen Folk song collection [@schaffrathEssenFolkSong1995].
I compare the Berkowitz Corpus to the Essen Folk Song Collection because importantly close in being that they both were written for some sort of vocal performance.
The Berkowitz corpus was specifically designed for pedagogical purposes whereas the Essen is more ecologically reflective of melodies originating from a diversity of sources.
Though given that they are both generally vocal melodies and  both come from Western sources, there presumably would be differences on between the two corpora on a large scale structure.
A second, more important reason for comparing this corpus with the Essen is that the Essen is one of the more heavily cited corpora used in the field of computational musicology and often taken as a proxy to represent the underlying expectation structure of Western music.
For example....... 
Much of this work makes claims about general level musical features, referencing the Essen dataset as reference.
In this context, the underlying assumption in this inference is that the Essen is a sample of the larger population of Western music borrowing underlying logic from frequentism as evident from the choice to examine these relationship like Huron did using frequentist statistics and the null hypothesis significance testing framework (Dienes chapter).
While of course this might be true,in order to have more evidence for this, would need to build more evidence.
This could come in the form of performing frequentist statistical tests on data to reject null looking at the probability of the data given the hypothesis, tho on large data sets that is a bad idea.
Or could be talking about modeling these things in terms of Bayes, which would be modeling data looking at probability of the hypothesis given the data.
Either way, providing more evidence for previous claims depends on, as noted above, finding new evidence for claims with new data. 

Below I do a corpus analysis of both the Berkowitz an Essen on a descriptive level, then take a case study example and look into it where MELODIES DESCEND to see.

* Distribution of Solfa
* Distribution of Notes 
* Distribution of bi-gram probabilities of them
* Then subtract the matrices to show where the differences in the bi-grams are

So knowing that they are similar in some aspects, want to then ask if some of the assumptions hold.
For example, THEY argued that there is a descent in vocal tract.
Found evidence using corpus study.
This was followed up and published by Shanahan.
So if it is true, should see it again in this corpus.

In order to do that, ran THIS ANALYSIS over the humdrum data.
And found that SENTENCE HERE.
This is reflected in FIGURE HERE.

From this we can conclude that....
And this is an example of using new data to test invariance of claims under different conditions.
But to return to question of assumptions, what population is are both of these corpora assumed to originate from.
And what, in fact are the assumptions of other types of corpus studies.
As said above, assumption here is that often in many studies corpora share an assumed sample population relationship. 
This is OK from descriptive point of view, but becomes difficult to then apply any sort of inferential statistical tests.
Requires answering a question of what are the bounds of the population?
In historical studies, this is never possible.
No more Clara Schumann.
In studies that captured Essen over time, yes can be representative.
But work in transmission of song reflects that just like culture evolves, so does music.
This is discussed by Savage.
So the more important question then becomes what does it mean to be able to replicate these findings and find what is invariant with another corpus.
If this is not possible, epistemologically this prohibits from NHST.
Frequentism is not the only way to conceptualize statistical relationship, could be Bayes.
More often than not this also more reflects the intuition that people want of probability of hypothesis given data rather than what NHST gives of P data given hypothesis.
Concrete answer to this question is beyond the scope of this chapter, important to end by saying that people who do use corpus methodologies need to be explicit about what they are assuming their corpora to represent.



