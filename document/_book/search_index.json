[
["index.html", "Modeling Melodic Dictation Chapter 1 Significance of the Study 1.1 Claims about need to join the worlds of theory and pedagogy 1.2 Chapter Overview", " Modeling Melodic Dictation David John Baker 2018-10-02 Chapter 1 Significance of the Study All students pursing a Bachelor’s degree in Music from universities accredited by the National Association of Schools of Music must learn to take melodic dictation (“National Association of Schools of Music Handbook” 2018 Section VIII.6.B.2.A). Melodic dictation is a cognitively demanding process that requires students to listen to a melody, retain it in memory, and then use their knowledge of Western musical notation in order to recreate the mental image of the melody on paper in a limited time frame. As of 2018 there are 647 Schools of Music belonging to National Association of Schools of Music (NASM) CITE WEBSITE, meaning that hundereds of students every year will be expected to learn this challenging task as part of their Aural Skills education. The logic being that as one improves in their abiliy to take melodic dictation, this practice of critical and active listening develops as a means to improve one’s ability to “think in music” and thus become a more compotent musician. While learning Aural Skills has been a hallmark of being educated within the Western conservatory tradition, the rationale behind both the how and why of aural skills is often thought of as being esoteric. Throughout the past century, people have disagreed on exactly how one does go about learning a melody with different areas of research each attacking the problem from a different angle. Despite its ubiqiquity in curricula within School of Music settings, research on topics pertain to how aural skills are acquired is limited at best. [Citations here about the cosntant calls butler, klondoski, pembrook] The fields of music theory and cognitive psychology are best positioned to make progress on this question, but often the skills required to be well versed ein ither of these subjects are disparate, published in other journals, and the research with overlap is scarce. This problem is not new and there have been repeated attempts to bridge the gap between practioners of aural skills and people in cognitive psycholgy CITES. Literature from music theory has establisehd conceptual frameworks regarding aural skills Karpinski (2000) and the relavint cognitive psychology literature has explored factors that might contribute to melodic perception (SCHMUKLER SYNERR 2016 2016), and there exists applied literature from the world of music education (CITES). However, despite these siloed areas of research, we as music researchers do not have an a concrete understanding of exaclty what contributes to HOW individuals learn melodies (HALPERNBARLETT2010). This is peculiar since “how does one learn a melody” seems to be one of the fundamental questions to the fields of music theory, music psychology, as well as music education. Given this lack of understanding, it becomes even more peculiar that this lack of convergence of evidence is then unable to provide a solid baseline as to what student in their aural skills classrooms can be expected to do. (Also something about we should really know this if we are going to grade people on this ability). While no single dissertation can solve any problem completely, this dissertation aims to fill the gap in the literature between aural skills practitioners (theorists and educators) and music psychologists in order to reach conclusion that can be applied systematically in pedagogical contexts. In order to do this I draw both literatures (music and science) in order to demonstrate how tools from both cognitive psychology as well as computational musicology can help move both fields forward. Some line here about if we really want to understand what is happening we need to know about causal factors going on here and have experimental manipulation and things like making models of the whole thing or talk about what Judea Pearl thinks about the ability to do some sort of causal modeling with diagrams. Great to rely on some sort of anecdoatal evidence, but if we are going to put things on the line with our education then we need to be able to make some sort of falsifiable claims about what we are doing. Can only do that through the lens of science. 1.1 Claims about need to join the worlds of theory and pedagogy (Butler 1997) (Klonoski 2000) - perceptual hierarchy, not enough info from aural skills training (Karpinski 2000) - “There is indeed a gap between the disciples of music cognition and aural skills training”, GK says that one of his goals is to bridge that gap, and he does. 1.2 Chapter Overview In this first chapter, I introduce the process of melodic dictation and discuss factors that would presumably could play a role in taking melodic dictation. The chapter introduces both a theoretical backgorund and rationale for using method form both computational musicology and congitive psychology in order ot answr quesitona bout how individuals learn melodies. I argue that tools for understanding this best because as we currently understand it, I see us operating in a Kuhnian normal science where much can be learned by just using the tools in front of us. This chapter will clearly outline the factors hypothesized to contribute to an individual’s abilit to learn melodies, incorporating both individual and musical parameters. The chapter ends with a discussion some of the philosophical/theoretical problems with attempting to measure thigns like this (is it just a party trick?) and establishes that I will be taking a more polymorphic view of musicianship in order to answer this question. The second chapter of my dissertation focuses on the history and current state of aural skills pedagogy. Tracing back its origins to the practical need to teach musical skills back with Guido d’Arezzo, I compare and contrast the different methodological approaches that have been used, along with their goals. The third chapter discusses previous work that examines individual factors thought to contribute to one’s ability to perform an aural skills task, and it will discuss results from an experiment contributing to a discussion of how individual differences could contribute to how a person learns melodies. Turning away from individual differences and focusing on musical features, in the fourth chapter I plan to discuss how music researchers can use tools from computational musicology as predictive features of melodies. Inspired by work from computational linguistics and information theory, recent work in computational musicology has developed software capable of abstracting features thought to be important to learning melodies, such as note density and ‘tonalness’ (Müllensiefen, 2009). Talk a bit about how this has been also looked at before in the music education community. While these features have been used in large scale, exploratory studies, work in this chapter will discuss how these features could be used in controlled, experimental studies as a stand-in for the intuition many music pedagogues have when determining difficulty of a melody in a classroom setting. In my fifth chapter, I introduce a novel corpus of over 600 digitized melodies encoded in a queryable format. This dataset will also serve as a valuable resource for future researchers in music, psychology, and the digital humanities. This chapter begins with a discussion of the history of corpus studies, noting their origin outside of music, their current state in music, and their limitations. This chapter, encapsulating the encoding process, the sampling criteria, and the situation of corpus methodologies within the broader research area, will go over summary data and also talk about how it could be used to generate hypotheses for future experiemnts (n-gram stuff based on patterns) . Lastly, in the final chapter, I will synthesize the previous research in a series of melodic dictation experiments. Stimuli for the experiments are selected based on the abstracted features of the melodies and are manipulated as independent variables based on the previous theoretical literature. I then model responses from the experiments using both individual factors and musical features in order to predict how well an individual performs in behavioral tasks similar to some of my previously published research (Baker &amp; Müllensiefen, 2017). Here I also note important caveats in scoring melodic dictation, referencing some other of my own work on using metrics, such as edit distance (Baker &amp; Shanahan, 2018), to discuss similarities between the correct answer and an individual’s attempts at dictation. Results from the final chapter will be discussed with reference to how findings are applicable to pedagoges in aural skills settings. Recommendations will be made building on current conceptual frameworks (Karpinski, 2000). References "],
["intro.html", "Chapter 2 Theoretical Background and Rationale 2.1 What is melodic dictation? and Why? 2.2 Individual Factors 2.3 Musical Factors 2.4 Modeling and Polymorphism of Ability 2.5 Conclusions", " Chapter 2 Theoretical Background and Rationale 2.1 What is melodic dictation? and Why? Melodic dictation is the process in which an individual hears a melody, retains it in memory, and then uses their knowledge of Western musical notation to recreate the mental image of the melody on paper in a limited time frame. For many, becoming proficient at this task is at the core of developing one’s aural skills (Karpinski 1990). For over a century, music pedagogues have valued melodic dictation1 which is evident from the fact that most aural skills texts with content devoted to honing one’s listening skills have sections on melodic dictation (Karpinski 2000). Additionally, any school accredited by the National Association of Schools of Music in North America requires students to learn this skill (“National Association of Schools of Music Handbook” 2018, sec. VIII.6.B.2.A). Yet despite this tradition and ubiquity, the rationales as to why it is important for students to learn this ability often comes from some sort of appeal to tradition or underwhelming anecdotal evidence. The argument tends to go that time spent learning to take melodic dictation results in increases in near transfer abilities after an individual acquires a certain degree of proficiency learning to take melodic dictation. Rationales given for why students should learn melodic dictation has even been described by Gary Karpinski as being based on “comparatively vague aphorisms about mental relationships and intelligent listening” (Karpinski 1990, 192), thus leaving the evidence for the argument for learning to take melodic dictation not being well supported. Some researchers have taken a more skeptical stance and asserted that the rationale for why we teach melodic dictation deserves more critique. For example, Klonoski in writing about aural skills education aptly questions “What specific deficiency is revealed with an incorrect response in melodic dictation settings?” (Klonoski 2006). Earlier researchers like Potter, in their own publications, have noted how they have been baffled that many musicians do not actually keep up with their melodic dictation abilities after the class ends (Potter 1990), but presumably go on to have successful and fulfilling musical lives. Additionally, suggesting that people who can hear music and then are unable to write it down, thus are unable to think in music (Karpinski 2000), seems somewhat exclusionary to musical cultures that do not depend on any sort of written notation. Though despite this skepticism towards the topic, melodic dictation remains at the forefront of many aural skills classrooms. The act of becoming better at this skill may or may not lead to large in increases in far transfer of ability, but used as a pedagogical tool, teaching students to take melodic dictation brings with it concepts that have been deemed relevant to the core of undergraduate music training. While there has not been extensive research on melodic dictation research in recent years– in fact Paney (2016) notes that since 2000, only four studies were published that directly examined melodic dictation– this skill set sits on the border between literature on learning, melodic perception, memory, and music theory pedagogy. Understanding and modeling exactly how melodic dictation works remains as a untapped watershed of knowledge for the field of music theory, music education, and music perception and is deserving of much more attention. In this chapter I examine literature both directly and indirectly related to melodic dictation by first reviewing the prominent four step model put forth by Karpinski in order to establish and describe what melodic dictation is. After describing his model, I then critique what this model lacks and clarify what is missing by providing a taxonomy of parameters that presumably would contribute to an individual’s ability to take melodic dictation. Using this taxonomy, I then review relevant literature and assert that the next steps forward in understanding how melodic dictation works come from examing the process both experimentally and computationally. It has been nearly two decades since Aural Skills Acquistion was first published as the first major step to finally build a bridge between the field of music cognition and music theory pedagogy (Butler 1997; Karpinski 2000; Klonoski 2000) and as with all public works, they need to be maintained?2 2.1.1 Describing Melodic Dictation Much of the foundational theoretical work on the topic of melodic dictation comes from Gary Karpinski. Summarized most recently in his Aural Skills Acquisition (Karpinski 2000)– though first presented in an earlier article (Karpinski 1990)– Karpinski proposes a four-step model of melodic dictation.3 The four steps of Karpinski’s model include Hearing Short Term Melodic Memory Musical Understanding Notation and occur as a looping process depicted in Figure 1. The model is discussed extensively in both this original article (Karpinski 1990) and throughout the third chapter in his book (Karpinski 2000). [FULL SCAN HERE EVENTUALLY OF FIGURE 1] 2.1.1.0.1 FIGURE 1 STAND IN Hear (along with Portion B) Remember (Portion A only) Understand Temporal Pulse Meter Rhythmic proportions Pitch Tonic Scale degree of starting pitch Scale degree of subsequent pitches Stepwise Groups Each skip treated as new starting pitch Notate What has been heard, remembered, understood Karpinski’s hearing stage involves the initial perceptions of the sound at the psychoacoustical level and the listener’s attention to the incoming musical information. If the listener is not actively engaging in the task because of factors such as “boredom, lack of discipline, test anxiety, attention deficit disorder, or any number of other causes” then any further processes later down the model will be detrimentally effected. Karpinski notes that these types of interferences are normally “beyond the traditional jurisdiction of aural skills instruction”, but I will later argue that the concept of willful attention, when re-conceptualized as working memory, may actually play a larger role in the melodic dictation process than is claimed here. The short-term melodic memory stage in his process is where musical material is held in active memory. From Figure 1 it appears that the stage is not conceptualized as an active process where something like active rehearsal would occur, but rather just consists soley of passive mental representation. Though Karpinski does not posit any sort of active process in the short term melodic memory stage, he does suggest there are two separate memory encoding mechanisms, one for contour, and one for pitch. He arrives at these two mechanisms by using both empirical qualitative interview evidece as well as noting literature from music perception that supports this claim for contour (Dowling 1978; Dewitt and Crowder 1986) and literature suggesting that memory for melodic material is dependant on enculturation (Oura and Hatano 1988; Handel 1989; Dowling 1990). Since its publication in 2000, this area of research has expanded with other reearchers also demonstrating the effects of musical acculturation via exposure (Eerola, Louhivuori, and Lebaka 2009; Stevens 2012; Pearce and Wiggins 2012). In describing the short term melodic memory stage, Karpinksi also details two processes that he believes to be nesscary for this part of melodic dictation: extractive listening and chunking. Noting that there is probably some sort of capacity limit to the perception of musical material, citing Miller (1956), Karpinski explains how each strategy might be used. Extractive listening is the process in which someone dictating the melody will selectivly remember only a small part of the melody in order to lessen the load on memory. Chunking is the process in which smaller musical elements can be fused together in order to expand how much information can be actively held in memory and manipulated. The concept of chunking is very helpful as a pedagogical tool, but as detailed below, is a complicated concept to pin down how it works. After some musical material is extracted, then represented in memory, the next step in the process is musical understanding. At this point in the dictation the dictator needs to take the extracted musical material that is represented in memory and the use their music theoretic knowledge in order to comprehend any sort of hierarchical relationships between notes, common rhythmic groupings, or any sorts of tonal functions. This is the point in the process where solimization of either or both pitch and rhythm, and musical material might be understood in terms of relative pitch. In the model solimization takes place later, but it is worth questioning if it is possible to dissacociate relative pitch relations from the qualia of the tones themselves (Arthur 2018). For Karpinski, the more quickly what is represented in musical memory can be understood, the more quickly it can then be tranlated at the final step of notation. Notation, the final step of the dictation loop, requires that the individual taking the notation have sufficient knowledge of Western musical notation so that they are able to translate their musical understanding into written notation. This last step is ripe for errors and has proved problematic for researchers attempting to study dictation (Taylor and Pembrook 1983; Klonoski 2006). It is also worth highlighting is that it is difficult to notate musical material if the individual who is dictating does not have the requisite musical category and knowledge for the sounds. Lack of this knowledge will limit an individual’s ability to translate what is in their short term melodic memory into notation, even if it is perfectly represented in memory! The final parts of the chapter, Karpinski notes that other factors like tempo, the length and number of playings, and the duration between playings will also play a role in determining how an individual will perform on a melodic dictation. While this framework can help illuminate this cognitive process and help pedagogues understand how to best help their students, presumably there are many more factors that contribute to this process. The model as it stands is not detailed enough for explanatory purposes and lacks in two areas that would need to be expanded if this model were to be explored experimentally and computationally. First, having a single model for melodic dictation assumes that all individuals are likely to engage in this sequential ordering of events. This could in fact be the case4, but there is research from music perception (Goldman, Jackson, and Sajda 2018) and other areas of memory psychology such as work on expert chess players (Lane and Chang 2018) that suggests that as individuals gain more expertise, their processing and categorization of information changes. Additionally, different individuals will most likely have different experiences dictating melodies based on their own past listening experience, an area that Karpinski refers to when citing literature on musical enculturation based on statistical exposure. The model does not have any flexibility in terms of individual differences. Second, the model presumes the same sequence of events for every melody. As a general heurstic for communicating the process, this process is generalizable, but intuition would suggest that treating all melodies the same is not going to lead to having a robust model. For example, on page 103, Karpinski suggest that two listenings should be adequate for a listener with few to no chunking skills to listen to be able to dictate a melody of twelve to twenty notes. This process might generalize to many tonal melodies, but presumably different strategies in recognition would be involved in dictating the two melodies of equal length shown in Figure 2 and 3. Figure 2.1: Melodies of Equal Length Figure 2.1: Melodies of Equal Length Presumably different people with different levels of abilities will perform differently on different melodies and while helpful as a pedaogogical tool, this one size-fits-all approach to melodic dictation is not robust. This agnosticism for both variability for melodic and individual differences serves as a stepping off point for this study. In order to have a more through understanding of melodic dictation, there needs to be a model that is able to accomodate the exhaustive differences at both the individual and musical levels. Additionally, the model should be able to be operationalized so that it can be explored in both experimental and computational settings. By explicitly stating variables thought to contribute and noting how melodic dictation works, it will give the community a better sense of the melodic dictation process, which will then enable a more through understanding of melodic perception and subsequently allow for better teaching practices in aural skills classrooms. At this point, it is worth stepping back and noting that the sheer amount of variables at play here is cumbersome and almost haphazard. In order to better understand and organize factors thought to contribute to this process, it would advantagous for future research to taxonomize the multitude of features thought to contribute to melodic dictation. In doing this, it wil allow for a clearer picture of what factors might contribute and what literatures to explore in order to learn more about them. The taxonomy that I propose appears in Figure 4 and bifucates the possible factors thought to affect an individual’s ability to take melodic dictation into two categories: individual parameters and musical parameters. Each of these two categories can then be split again into cognitive and environmental parameters as well as structural and experimental factors respectively. Below I expand on what these categories entail, then explore each in depth. Figure 2.2: Taxonomy of Factors Contributing to Aural Skills The individual parameters split broadly into cognitive factors, or factors of people that are relatively consistent with people over time and could be understood as largely being governed by nature. The other category of this division consist of factors that change with training and exposure and could be understand as largely being governed by nurture. This second set of parameters are the environmental factors. These categories are not deterministic, nor exclusive, and almost inevitably interact with one another.5 For example, it would be possible to imagine an individual with higher cognitive ability, the oppertunity to have a high degree of training early on in their musical career, and personality traits that are associated with higher learning aptitudes. This individual’s musical perception abilities might be markedly different than someone with lower cognitive abilities, no opertunity for individualized training, come from a lower socio-economic status, and not have a general inclination to even take music lessons. This variability at the individual level might then lead to differences in their ability to take melodic dictation. Complementing the individual differences, there would also be differences at the musical level which in turn divides into two categories. On one hand exists the structural aspects of the melody itself. These are aspects of the melody that would remain invariant when written down on a score. Parameters in this category would include features generated by the interval structure of the pitches over time that allow the melody to be categorically distinct from other melodies. These structural features are then complimented by the experimental features which are emergent properties of the structrual relation of the pitches over time based on performance pratice choices. Examples of these parameters would include, key, tempo, note density, timbral qualities, and the amount of times a melody is played during a melodic dictation or emergent properties like a melody’s tonalness as computed through various metrics. This division is not an exhaustive, categorical divide. One could imagine exceptions to these rules where a melody is tranformed to the minor key, ornamented, and then played with extenive rubato and experienced as a phenomenologically similiar experience. Given all of these parameters that could contribute to the melodic dictation process, the remainder of this chapter will exploring literature using this taxonomy as a guide. The chapter conculdes with a reflection on operationalizing each of these factors and problems that can arise in modeling and reminds the reader about the dangers of statistical reification. These are important to note since from an empirical standpoint, both the task as well as the process of melodic dictation as depicted by Karpinksi resemble something that could be operationalized as both an experiment, as well as a computational model and if understood this way will be subjectd to the same types of critique. 2.2 Individual Factors 2.2.1 Cognitive Research from cognitive psychology suggests that individuals differ in their perceptual and cognitive abilities in ways that are both stable throughout a lifetime and are not easily influened by short term traning. When investigated on a large scale, these abilities– such as general intelligence or working memory capacity– predict a wealth of human behavior on a large scale ranging from longevity, annual income, ability to deal with stressful life events, and even the onset of Alzheimer’s disease (Ritchie 2015; Unsworth et al. 2005). Given the strength and generality of these predictors, it is worth investigating the extent that these abilities might contribute when investigating any modeling of melodic dictation. It is imporant to understand the degree to which these cognitive factors might influence aural skills abilities in order to ensure that the types of assesments that are given in music schools validly measure abilities that individuals have the ability to improve upon. If it is the case that much of the variance in a student’s aural skills grades can be attributed to something the student has little control over, this would call for a serious upheaval of the current model of aural skills teaching and assesment. Recently there has been a surge of interest in this area6 which could be attributed to the fact that educators are picking up on the fact that cognitive abilities are powerful predictors and need to be understood since they inevitably will play a role in pedagogical settings. Before diving into a discussion regarding differences in cognitive ability, I should note that sometimes ideas regarding differences in cognitive ability been hostily received (citation against people talking about IQ) and for good reasons. Research in this area can and has been taken advantage to further specious ideologies, but often arguments that assert meaningful differences in cognitive abilities between groups are founded on statistical misunderstandings and have been debunked in other literature (Gould 1996). Considering that, it then becomes very difficult to maintain a scientific commitment to the theory of evolution (Darwin 1859) and not expect variation in all aspects of human behavior, with cognition falling within that umbrella. Even given this statement, measuring a theoretical construct such as an aspect of cognition desereves to be examined since the ability to validly and reliably measure an individual’s cognitive ability is a fundmental assumption of this study. 2.2.2 Measuring Intelligence Attempting to measure and quantify aspects of cognition go back over a century. Even before concepts of intelligence were posited by Charles Spearman and his conception of g (Spearman 1904), scientists were interested in establishing links between an individual’s mental capacities and some sort of physical manifestation. The origins of this area of research have been critiqued on the basis that the early work implicitly tended to validate preconceptualized beliefs on the superiority of certain groups of peoples and used methodlogies that today would be considered risible. For example, BROCA thought he could get at intelligence by measuring skulls. OR THIS GUY WHO POST HOC/POST MORTUM ASSIGNED GREATNESS RATINGS While not immediatly relevant to current thinking in cognitive psychology, work from both Broca and XXX was continued by the American herediterian school of IQ (page 187 in Gould) and the early research done by Alfred Binet on IQ took inspiration from Broca. This lineage of ideas has often been used to tarnish systematic investigations into differences in cognitive ability, which from their outset were to initially funded by the French governement to identify children struggling in the classroom so that they could be given special attention. Bient was the initial developer of the idea of an intelligence quotient or IQ7 and provided one of the first ways to attempt to quantify a theoretical concept that was not capable of being manifested in the physical world. It was also around the same time that researchers like Cyril Burt and Charles Spearmean began developing their new theories of intelligence founded on the reification of factor analysis. In developing a battry of tests whose performance on one subtest could often reliabily predict performance on another– a manifestation referred to as the postive manifold– Spearman and Burt put forth a separate conception of intelligence based on the ability to solve problems without any sort of background information and referred to this ability a g for general intellgience. Though seemingly unrelated to the current state of thinking about cognitive abilities, Binet’s and Spearman’s ideologies about what intelligence is and how to measure it still represent two of the larger schools on cognitive ability. On one hand their idea that cognitive abilities are based upon a steady growth of incoming information that someone is able to manipulate once they retrieve from long term memor; on the other hand there is a school of thought that there is some sort of measureable construct, g that aids in the process of solving problems that do not depend on any sort of contextuxal information. Conceptualizing cognitive ability as these two different constructs inevitably leads to different types of measurements and subsequently what these constructs are then able to predict in terms of human behavior. Without detailing entire histories of both lines of thought, Binet’s conceptulization manifested into an argument for general crystallized intelligence or Gc, or the ability to solve problems based on previously acquired skills. Spearman and Burt’s ideas about g school reflect a belief that individuals have some sort of latent cognitive ability to draw on to perform mental tasks. The cognitive psychology literature has noted that g often shares a statistically equivalent relationship to idea conceptualized as general fluid intelligence Gf, or the ability to solve problems in novel situations Cattell, 1971; Horn, 1994). This distinction between Gf and Gc is different than that of g, but again it should be noted that Gf and g share a statistically identical relationship Matzke, Dolan, and Molenaar (2010). These conceptions of intelligenec and cognitive ability aslo differ from more current theories that sythesize these previous areas of research (Kovacs and Conway 2016). Even though both of these constructs are powerful predictors on a large scale and do predict things like educational success, income, and even life expectancy (Ritchie 2015)– even when other variables like socioeconomic status are held constant. Yet despite this, only conceptualizing cognitive abilities in terms of intelligence does not fully explain the diversity of human cognition. Another large area in the field of cognitive psychology is the area of working memory capacity. In addition to concepts of intelligence, be it Gf or Gc, the working memory capacity literature also is directly relevant to work on melodic dictation for reasons discussed below. 2.2.3 Working Memory Capacity Working memory is one of the most investigated concepts in the cognitive psychology literature. According to Nelson Cowan, the term working memory generally refers to the relativly small amount of information that one can hold in mind, attend to, or, technically speaking, maintain in a rapidly accesible state at one time. The term working is mean to indicate that mental work requires the use of such informaiton. (p.1) (Cowan 2005) The term, like most concepts in science, does not have an exact definition, nor does it have a definitive method of measurement. While there is no universally recognized first use of the term, researchers began to postulate that there was some sort of system that mediated incoming sensory information with the world with the information in long term storage using modular models of memory in the mid-twentieth century. Summarized in (Cowan 2005), one of the first modal models of memory was proposed by (???) and later expanded by (???). As seen in FIGURE X, both models here posit incoming information that is then put into some sort of limited capacity store. These modal models were then expanded on by Baddeley and Hitch (Baddeley and Hitch 1974) in their 1974 chapter with the name Working Memory, where they proposed a system with an central executive module that was able to carry out active maintenance and rehearsal of information that could be stored in either a phonological store for sounds or a visual sketchpad for images. Figure 2.3: Schematics of Models of Working Memory taken from Cowan, 2005 Later revisions of their model also incorporated an episodic buffer (???) where the modules were explicitly depicted as being able to interface with long term memory in the rehearsal processes. The model has even been expanded upon by other researchers throughout its lifetime. The most relevant to this study is by (Berz 1995), who postulated adding a musical rehearsal loop to the already established phonological loop and visual spatial sketchpad. While Berz is most likely correct in asserting that the nature of storing and processing musical information is different to that of words or pictures and there has been experimental evidence to suggest this (???) that has been interpreted in favor of multiple loops (???) , it does introduce the theoretical problem of multiple stores which has been addressed by other researchers. In addressing the problem of explicitly stating which rehearsal loops do and do not exist, Nelson Cowan proposed a separate model (???; Cowan 2005) dubbed the Embedded Process Model which do not claim the existence of any domain specific module (e.g. positing a phonological loop, visual spatial sketchpad) but is rather based on an exhaustive model that did away with the problem of asserting specific buffers for new types of information. In Cowan’s own words comparing his model from that of Baddeley: The aim was to see if the description of the processing structure could be exhaustive, even if not complete, in detail. By analogy, consider two descriptions of a house that has not been explored completely. Perhaps it has only been examined from the outside. Baddeley’s (1986) approach to modeling can be compared with hypothesizing that there is a kitchen, a bathroom, two equal-size square bedrooms, and a living room. This is not a bad guess, but it does not rule out the possibllity that there actually are extra bedrooms or bathroom, that the bedroom space is apportioned into two rooms very different in size, or that other rooms exist in the house. Cowan’s (1988) apporach, on the other hand, can be compared with hypothesizing that the house includes food preparating quarters, sleeping quarters, batroom/toilet quarters, and other living quarters. It is meant to be exhaustive in that nothing was left out, even though it is noncommital on the details of some of the rooms. p.42 CITATION. The system is depicted in the bottom tier of TABLE X, and conceptualizes the limited amount of information that is readily available as being in the focus of attention, with activated sensory and categorical features of what is in the focus of attention to be accessible nearby. Moving further from the locus of attention is long term memory, whose content can be turned to by using the central executive to access non-immediately available information. In contrast to the modular approaches, Cowan’s framework does not require the researchers to specify exactly how and where each the incoming information is being stored which makes it advantageous for studying complex stimuli such as music and melodies. In addition to having multiple frameworks for studying working memory capacity, there is also the problem of limits to the working memory system, often referred to as the working memory capacity. Most popularized by Miller in his famous (Miller 1956) speech turned article, Miller suggests out of jest that the number 7 might be worth investigating, which has been used as a point of reference for many researchers since then. It is worth nothing that Miller has since gone on record as noting that using 7 (plus or minus 2) was a rhetorical device used to string together his speech (Miller 1989). Nevertheless, while the number seven is most likely a red herring, it did inspire a large amount of research on capacity limits. In the decades since the number 7 has been reduced to about 4 (???) and research around capacity limits has been investigated using a variety of novel tasks, most noteable the complex span task CITATION. When used as predictors in both higher and lower cognitive tasks, measures of working memory capacity predict performance well and additionally tend to be stable across a lifetime (Unsworth et al. 2005). Given its predictive strength as well as its direct similarity to tasks of melodic dictation, a in depth look at the literature is warranted. Clearly an individual’s ability to take in sensory information, maintain it in memory, actively carry out other tasks (like notating said melody) are almost identical to tasks of working memory capacity. Before venturing onward from this striking parallel, tasks investigating working memory capacity differ from melodic dictation tasks in a few key ways. The first is that musical information is always sequential: a melodic dictation task would never require the student to recall the pitches back in scrambled orders. Serial order recall is an important characteristic in the scoring and analyzing of working memory tasks (Conway et al. 2005), but musical tones do not appear in random order and are normally in discernable chunks as discussed by Karpinski(Karpinski 2000). The use of chunks is pervasive in much of the memory literature, but often is used as more of a heuristic to help explain that information in the environment and why it is often grouped together. Of the problems with chunking, most are related to music and have relevance to melodic dictation. Below I review the problems with chunking noted by Cowan (Cowan 2005), and any pertitant music psychology literature. Chunks may have a hierarchical organization. Tonal music has historically been understood to be hierarchical (Krumhansl 2001; Meyer 1956; Schenker 1935) with the study for memory for tones being confounded by some pitches being undestood by their relation to structurally more important tones. The working memory load may be reduced as working memory shifts between levels in hierarchy. If an individual understands a chunk to be something such as a major triad, the load on working memory would be less since it that information could be understood as a singular chunk. Chunks may be the endpoints of a continuum of associations. Pairing a group of tones together that might be functionally anomolous like… Chunks may include asymmetrical information. More tonal possibilities are possible from a stable note like tonic or dominant, whereas in a tonal context, a raised scale degree #\\(\\hat{4}\\) when understood in a functional context would be taken as having stricter transitional probabilities (#\\(\\hat{4} \\rightarrow \\hat{5}\\)). There may be a complex network of associations. If a set of pitches sounds like a similar set of pitches from long term memory , the information coming in can not be understood as being separate units of working memory. Chunks may increase in size rapidly over time. Three tones that are seemingly unrelated when incoming like E4, G5, C5 might enter sensory perception as three different tones, but then be fused together when they are understood as one chunk– a first inverstion major triad. Information in working memory may benefit from rapid storage in long term memory. Given the amount of patterns that an individual learns and can understand, as soon as something is fused, it could be encoded in long term memory, especially if there is a salient feature in the incoming melodic information such as the immediate recognition of a mode or cadence. The points by Cowan are important to acknowledge in that it it not possible to directly lift work and paradigms from working memory capcacity to work in music perception. That said, the enormous amount of theoretical frameworks put forward by the working memory liteature when understood in conjunction with theories in music psychology such as implicit statistical learning (Saffran et al. 1999) can provide for new, fruitul theories. Past reserachers have noted the strength and predictive abilities of literature from the working memory capacity as aiding research in music perception. In ending his article positing a musical memory loop to be annexed to the Baddley and Hitch modular model of working memory, Berz (Berz 1995) captures the power of this concept in the last sentence of his article and warns future reserachers that Individual differences portrayed in some music aptitude tests may [sic] represent not talent or musical intelligence but ability, reflecting differences in working memory capacity. p. 362 Berz’s assertion has not been exhausivly tested since first published in 1995, but the subject of music, memory, and cognitive abilities has been the focus of research of both psychologists and musicologists alike. Below I survey literature bordering on both music, as well as cognitive abiltity. 2.2.3.1 Working Memory Capacity and Music Of the papers in the music science literature that specifically investigates working memory, each uses different measures, though but all tend to converge on two general findings. The first is that there are some sort of enhanced memory capabilities in individuals with musical training. The second is that working memory capacity, however it is measured, often plays a significant role in musical tasks. Evidence for the first point appears most convincingly in a recent meta analyses by Talamini and colleagues (???) who demonstrated via three separate meta-analyses that musicians outperform their non-musical counterparts on tasks dealing with long-term memory, short-term memory, as well as working memory. The authors also noted that the effects were the strongest in working memory tasks where the stimuli were tonal, which again suggests an advantage of exposure and understanding of the hierarchical organization of musical materials. In this meta-analyss and others investigating music and cognitive ability, it is important to be reminded that the direction of causality still from these studies cannot be determined using these statistical methodologies. While it might seem that musical training tends to lead to these increases, it is also possible that higher functioning individuals will self select into musical activities. Even if there is no seletion bias in engaging with musical activity it also remains a possiblity that of the people that do engage with musical activity, the higher functioning individuals will be less likely to quit over a lifetime. In terms of musical performance abilities, working memory capacity has also been shown to be a significant predictor. Kopiez and Lee suggested that working memory capacity should to contribute to sight reading tasks based on research where they found measures of working memory capacity, as measured by a matrix span task, to significantly correlated with many of their measures hypothesized to be related to sight reading ability in pianists at lower difficulty grading (???; ???). Following up on this work on sight reading, Meinz and Hambrick (???) found that working memory capacity, as measured by an operation span task, a reading span task, rotation span task, and a matrix span task was able to predict a small amount of variance \\(R^2=.074(0.067)\\) above and beyond that of deliberate practice alone \\(R^2=.451(.441)\\) in a sight-reading task. More recently, two studies looking at specific sub groups of musicians have shown working memory capacity to significantly contribute to models of performances on musical tasks related to novel stimuli. (???) found that although no differences were found between pianists and conductors in measures of working memory capacity as measured via a set of span tasks, conductors showed superior performance in their attention flexibility. Following up on this line of research (Nichols, Wöllner, and Halpern 2018) used the same battery of working memory tasks and found that jazz musicians excelled over their classically trained counterparts in a task which required them to hear notes and reproduce them on the piano. The authors also noted that of their working memory battery, based on standard operation span methods (???), that the auditory dictation condition scored surprisingly low and further research might consider further work on dictation abilities. Additionally (???) found that working memory capacity, as measured by a backwards digit span and operation span, to be successful predictors in a tapping task requiring sensory motor prediction abilities. As mentioned above, each of these tasks where working memory was a significant predictor of performance occured where the task involved active enagement with novel musical material. The growing evidence in this field suggests that the advantage of working memory capacity to be greatest in both musically trained people, dealing with novel information, using tonal materials. Since all three of these factors are related to melodic dictation, it would seem sensible to continue to include these measures in tasks of musical perception and continue Berz’s assertion that research in music percetion could inadvertently be picking up on individual differences in working memory abilities. 2.2.4 General Intelligence As discussed above gf has a long history, some good some bad. Thing is that it can be really predictive of many things and people def do try incorporate it into music research. And statistically speaking, terms use IQ, but note that IQ and Gf’s correlation tend to be statiscally idential (Kovacs and Conway 2016) and many measures of IQ are done with Ravens as seen below. One of the big problems with this is establishing effects of causality looking at music. Could be that factors outside of music play a role like personal views of ability (Müllensiefen et al. 2015) , socio economic status, and personality. 2.2.4.1 Papers that suggest GF plays a role As reviewed in (Schellenberg 2017), both children and adults who engage in musical activity tend to score higher on general measurses of intelligence than their non-musical peers (Gibson, Folley and Park, 2009; Hille et al., 2011; Schellenberg, 2011a; Schellenberg and Mankarious, 2012). with the duration of training sharing a relationship with the extent of the increases in IQ (Degé, Kubicek and Schwarzer, 2011a; Degé, Wehrum, Stark and Schwarzer, 2015; Corrigall and Schellenberg, 2015; Corrigall, Schellenberg and Misura, 2013; Schellenberg, 2006). Though many of these studies are correlational, they also have made attempts to control for confounding variables like socio-economic status and parental involvment in out of school activities. (Corrigall et al., 2013; Degé et al., 2011a; Schellenberg, 2006, 2011a, 2011b; Schellenberg and Mankarious, 2012). Schellenberg notes the problem of smaller sample sizes in his review (Corrigall and Trainor, 2011; Parbery-Clark et al., 2011; Strait, Parbery-Clark, Hittner and Kraus, 2012) in that they normally do not reach significance. And also references evidence that when professional musicians are matched with non-musicians in the public, also do not seem to see these associations. Schellenberg, 2015 which Schellenberg takes as more evidence that it is actually just higher functioning kids that take music lessons. Additionally, Schellenberg remains skeptical of any sorts of causal factors regarding increases in IQ (e.g., François et al., 2013; Moreno et al., 2009) noting methodlogical problems like how short exposure times were, or researchers who did not hold pre-exisiting cognitive abilitis constant (Mehr, Schachner, Katz and Spelke, 2013). (Corrigall, Schellenberg, and Misura 2013) (???) (Swaminathan, Schellenberg, and Khalil 2017) 2.2.5 Environmental 2.2.6 Long term memory and corpus with implicit Standing in contrast to factors that individuals do not have a much control over such as the size of their working memory capacity or factors related to their general fluid intelligence, most of the factors we believe contribute to someone’s ability to take melodic dictation have to deal with factors related to training and the environment. In fact, one of the tacit assumptions of getting a music degree revolves around the implicitly held belief that with deliberate and attentive practice, that an individual is able to move from novice to expertise in their chosen domain. The idea that time invested results in beneficial returns is probably best exemplified by work produced by ANDERS ERICKSON 1993 that suggests that performance at more elite levels has to do with deliberate practice. Below I review literature that supports this argument, since it’s no doubt that someone has to engage in something to be good at it. 2.2.7 Musical Training Papers that suggest practicing makes you better? It almost seems redundant to review literature in support of music practice leading to better results. List of those papers here 2.2.8 Aural Training Considering points that I make earlier about polymorphic views of musicality and ability. Harrison et al for latent variable approach (Harrison, Asmus, and Serpe 1994) Dictation has not been that well researched (Furby 2016) people try lots of things, not much evidence for peer tutoring (Furby 2016) These are things that people have suggested people trying to do : As noted in Furby 2016, researchers in the past have suggested a variety of techniques for improving their abilities in melodic dictation by isolating rhythm and melody [Banton (1995); Bland (1984); Root (1931); WILSON], listening attentively to the melody before writing (Banton 1995), recognizing patterns (Banton 1995; Bland 1984; Root 1931) and silently vocalizing while dictating (Klonoski 2006). 2.2.9 Sight Singing Often described as the other side of the same coin of melodic dictation, sight singing is an area of music pedagogy research that has had sparse attention paid to it given its prevelance in school of music curricula. Recently (Fournier et al. 2017) catalouged and categorized 14 different sub categories into four larger main cateogories while also providing commenatary on some of the current state of aural skills. Of the four large categories, they group them into reading mechanisms, sight singing, readings skills acquiskiton, and learnign support. The authors note a line of research that has documented that university students are often unprepared to sight-read single lines of music (Asmus, 2004; Davidson, Scripp &amp; Welsh, 1988; Fournier, 2015; Thompson, 2004; Vujović &amp; Bogunović, 2012) even though it is, like dictation, thought of as a means for deeper musical understanding. (DeBellis, 2005; Karpinski, 2000; Ottman, 1956; Rogers, 2004; Scripp, 1995; Scripp &amp; Davidson, 1994 The authors of Fournier et. al also note that sight-reading has been an active area of research due to the often reported relationship that performance on sight reading often predicts several studies have shown links between academic success in sight-singing and predictors such as entrance tests (Harrison, 1987, 1990, 1991; Ottman, 1956; Rodeheaver, 1972; Schleuter, 1983), academic ability (Chadwick, 1933; Harrison, 1990, 1991; Harrison, Asmus, &amp; Serpe, 1994; Rodeheaver, 1972), and musical experience (Brown, 2001; Dean, 1937; Furby, 2008; Harrison, 1990, 1991; Harrison et al., 1994; Thostenson, 1967). Learning to a fluid and compotent sight reader presumable bootstraps learning other musical skills, for the same reasons aural skills are taught in schools. Though since it’s not directly related and now starting to move away from things looking at dictation directly, time to turn attention to the other half of the taxonomy, the musical factors. CLOSING DISCUSSION ON PUTTING COGNIIVE TOGETHER The cognive stuff if you understand intelligence and WMC as just separate is short sited, need to incorproate it in some sort of process theory KOVACS AND CONWAY. 2.3 Musical Factors Transitioning to the other half of the taxonomy on figure X, the other main source of variation on any study looking at melodic perception, and consequently studies of melodic dictation, is the effect of the melody itself. I find it safe to assume that not all melodies are equally difficult to dictate and assert that variance in the difficulty the melody can partitioned between both structural and experimental aspects of a melody. As noted above, there is not a strict deliniation between these two categories since once could imagine drastic maniuplations in experimental parameters in order to result in a phenomenologically different experience of melody. Questions of transformations of melodies and musical similarity fall have been addressed in ohter research (Cambouropoulos 2009; Wiggins 2007) but are beyond the scope of this study. 2.3.1 Structural The notion that the music as represented by a score is able to provide insights towards understanding aspects about music is not new to music theory and anlaysis. Heinrich Schenker argued for an undertanding of tonal music (Schenker 1935) that asserted hierarchical relationships of notes on the musical surface in the early 20th century and has since been expanded upon by theorists over the past century SALTZER, SCHAKTER, ROTHSTEIN. Leonard Meyer in his Emotion and Meaning in Music (Meyer 1956) continued some of these lines of thought and was the first who put forward the idea that tethered the struture that earlier theorists wrote about and suggested that in addition to this struture being fundamental to the perception of the piece that there were also responsible for some aspects of the emotion and meaning listeners found in the piece. Meyer’s work since inspired a line of reserach investigating the perception of the structural aspects of music could be understood with the work of Eugene Narmor (Narmour 1990, 1992), Glenn Schellenberg (Schellenberg 1997), Elizabeth Hellmuth Margulis (Margulis 2005), David Huron (Huron 2006) and have inpsired computational, machine learning approaches to expectational frameworks in with work by Marcus Pearce (Pearce and Wiggins 2012). WHAT IS THE POINT OF ALL THIS RESERACH SETNECE These general models of melodic perception tend suggest that Meyer was correct in his assertion that computational methodologies could be used to better understand question of melodic perception and strucuture and that there are links between the structure of the music and its perception.8 Turning to studies examining melodic dictation with a focus on musical structure, the first study to examine it extensively was Ortmann in 1933 (Ortmann 1933). Ortamnn used a series of twenty five-note melodies in order to examine the effects of repetition, pitch direction, conjunct-disjunct motion (contour), interval size, order, and chord structure, all of which he deems to be the determinants of an individual’s ability to dictate melodic material. Though Ortmann did not use any statistical methods to model his data, he did assert that each of his determinants contributed to an individual’s ability to dictate musical material. This work was extended by (Taylor and Pembrook 1983) which additionally incoporated using musical skill as a predictor and additionally found evidence that these factors contributed to individual dictation abilities in a sample of 122 undergraduate students. Although the literature is generally sparce compared to other areas of music cognition, literature exploring the effects of structural characteristics on memory does exist. Long found that length, tonal structure, contour, and individual traits all contribute to performance on melodic dictation examinations and found that structure and tonalness to have significant, albeit small predictive powers in modeling (Long 1977). One problem with studies such as (Long 1977) is that they sometimes would make conspicuous methodloogical decisions such as elimnating individuals who were bad singers for the example. Not only does this reduce the spectrum of ability levels (assuming that singing ability correlates with dictation ability, a finding since which has been established (Norris 2003)), but is additinally flawed in that it is at odds both with the intuition that an individual’s singing ability cannot be taken as a direct representation of their mental image of the melody and is probably more related to the ability to have motor control over the vocal tract (Pfordresher and Brown 2007). Other researchers have also put forward other paramters thought to contribute like tempo (Hofstetter 1981) tonality (Dowling 1978) (Long 1977) (Pembrook 1986) (Oura and Hatano 1988) interval motion (Ortmann 1933; Pembrook 1986) length of melody (Long 1977; Pembrook 1986) number of presentations (Hofstetter 1981) [(Pembrook 1986)] context of presentation (Schellenberg and Moore 1985) listener experience (Long 1977; Oura and Hatano 1988) (Schellenberg and Moore 1985; Taylor and Pembrook 1983) familarity of style (Schellenberg and Moore 1985) Pembrook (1986) provides an extensive detailing of a systematic study to melodic dictation where they used tonality, melody length, and type of motion as variables in their experiment. They additionally also restricted their experimental melodies to those that were singable. The authors found all three variables to be significant predictors with tonality explaining 13% of the variance, length explaining 3% of the variance and type of motion explaining 1% of the variance. The paper also claims that people on average can hear and remember 10-16 notes, which is worth commenting that these 10–16 notes are dependent on the experimental context of the melodies played with the quarter note set to 90 beats per minute. Given the lack of consistent methodlogies in adminstration and scoring of these experiments it becomes difficult to find ways to generalize basic findings like expected effect sizes– especially when the original materials and data have not been recorded– but there is often interesting theoretical insights to be gleaned. For example (Oura 1991) used a sample of eight people to suggest that when taking melodic dictation, individuals use a system of pattern matching that interfaces with their long term memory in order to complete dictation tasks. While this paper does not bring with it exhaustive evidence supporting this claim, the idea is explored in detail in Chapter 6 the idea of pattern matching is used in conjunction with Cowan’s embeded process model of working memory. More recently the music education community has also began to do research around melodic dictation using both qualitative and quantitiatve methdologies. (Paney and Buonviri 2014) interviewed high school teachers on methods they used to teach melodic dictation and (Gillespie 2001) has done work on investigating methods as to best score melodic dictation. Other work by (Pembrook and Riggins 1990) surveyed various methodlogies used by instructurs in aural skills settings. Some of these studies consider aural skills as a totality like (Norris 2003) who provided quantiative evidence to suggest most aural skills pedagoge’s intuition that there is some sort of relationship between melodic dictation and sight singing. Looking at the notorious subset of students with absolute pitch (AP), (Dooley and Deutsch 2010) provided evidence demonstrated that students with AP tend to outperform their non-AP colleagues in tests of dication. [SOME OF THESE ARE CLEARLY EXPERIMENTAL AND NEED TO BE PUT THERE] Continuing exploring the pedagogical liteature, Naton Buonviri and colleagues have also made melodic dictation a central focus of some recent papers. Paney and Buonviri (2014) interviewed high school teachers on methods that they used to teach melodic dictation. N. Buonviri (2015) interviewed six sophomore music majors to find sucessful strategies that students enaged with when completing melodic dications. Paney (2016) reported beneficial effects to direct student’s attention and guide them through melodic dictation exercises suggesting that some sort of mental organizaton of the dication process is helpful. N. O. Buonviri and Paney (2015) found that having students sing a preparatory singing pattern after hearing the target melody, essentially a distractor task, hindered performance on melodic dictation. Buonviri (2015)… N. Buonviri (2015) found no effects of test presentation format (visual versus aural-visual) using a melodic memory paradigm. Buonviri (2017) reported no significant advatage to listening strategies while partaking in a melodic dictation test. 2.3.1.1 Recent Computational Musicology Work papers and findings Using symbolic features of the melodies themselves is not a novel approach as noted in the above literature attempting to predict performance on melodic dictations. Much of this work pre-dates recent advances in computational musicology such as the advent of technology like David Huron’s Humdrum (Huron 1994) and Michael Cutberth’s Music21 (Cuthbert and Ariza 2010) which now allows music researchers to systematically digitize symbolic musical material. In addition to creating accesible frameworks for encoding, the computational power availble exponentially exceeds that of what was availble in the 20th century and has opened up new possibilities in the computational modeling of music. While I reserve a longer discussion on the histories of computational musicology for the fourth chapter, relevant to this study is the additional ways it is now possible to abstract features from symbolic melodies beyond what was capable in studies such as Ortmann (1933) and Taylor and Pembrook (1983). An abstracted feature of a melody is an emergent property of the melody that results from performing some sort of calculation on the melody? This type of feature abstraction is in contrast to much of the work done in the field of music information retrivial which often relies on the recorded audio for feature abstraction and is addressed under Experimental features LINK THAT IN!. Abstracted symbolic features of melodies can largely be conceptualized as being static or dynamic. The above papers tended to use more simplisitc methods of figuring out parameters such as counting the notes by hand but with the advent of new encoding systems and more powerful computing power it is now possible to take on much more rigerious computational analyses. 2.3.1.2 Static Views of Computational Features/ FANTASTIC Static features of melodies work by summerizing some aspect of the melody as if it were to be experience in suspended animation. Using static features helps quantify something that might be intuitive about a melody or piece of encoded music. For example, something like David Huron’s contour class CITATION used in THIS STUDY USING THE ESSEN FOLK SONG ON ARCS can only be understood as a feature of the melody itself once the melody has been sounded and is recalled would be a static feature of a melody. Other examples include a melody’s global note density, normalized pairwise variability index (CITATION), and a melody’s tonalness as calculated by one of the various key profile algorithms (KRUMHANSL,ALBRECT AND SHANAHAN) These measures are useful when describing melodies and are predictive of various behavioral phenomena as detailed below, but at this point it has not been well established to what degree these summary features can be directly related to aspects of human behavior. The quintessential and most comprehensive toolbox example of this is Daniel Müllensiefen’s Feature ANalysis Technology Accesing STatistics (In a Corpus) or FANTASTIC (???). FANTASTIC is software that is capable summerizing musical material at for monophonic melodies. In additon to computing 37 features such as contour variation, tonalnesss, note density, note length, and measures inspired by computational linguistics (THAT BOOK OF GERAINT), FANTASTIC also calculates m-types (melodic-rhyhmic motives) that are based on the frequency distributions of melodic segements found genres of music. This is inspired by fact that repeition is key structure of music (Huron 2006) Work using the FANTASTIC toolboox has been sucessful in predicting court case decisions (???), predicting chart sucesses of songs on the Beatles’ Revolver (Kopiez and Mullensiefen 2011), memory for old and new melodies in signal detection experiments (???), memory for earworms (???; ???), memorability of pop music hook (???). In experimental studies, FANTASTIC has also been used to determine item difficulty (Baker and Müllensiefen 2017; Harrison, Musil, and Müllensiefen 2016) and has even been the basis of the development of a computer assistted platform for studying memory for melodies (???). 2.3.1.3 Dynamic In addition to using summary based features on melodies, it is also possible to model the perception of musical materials by using a dynamic approach that is dependent on the unfolding of musical material. First explored in CONKLIN, and then first published as a dynamic model of expectation in his doctoral dissertation, Marcus Pearce’s Informaton Dynamics Of Melody IDyOM models musical expectancy using various information theoretic concepts inspired by Claude Shannon (SHANNON). The model takes an unsupervised machine learning approach and calculates the information content of the amount of DECLARED n-grams in the corpus. As a model exploring expection for melody IDyOM has has been applied to a variety of settings LIST THEM HERE. The domain general application of IDyOM has given creedence to Meyer’s assertion that the enculturation of musical styles stems from statistical exposure to melodies and be somewhat refelective of the cogitive processes used in muscical perception. IDyOM has also been recently extended to look at expectation in multi-part chorales (SAUVE WORK) and expectations of harmony (HARRISON WORK). (???; ???) The advantage of using a dynamic approach is that it theoretically reflects real time perception of music with the structural characeristics of the music mapping on to real human behavior. 2.3.2 Experimental Advantage of vocal melodies paper MIR stuff Stuff out of education stuff that is also experimental 2.4 Modeling and Polymorphism of Ability Given the current state of cognitive psychology and psychometrics, as well as recent advances in computational musicology, the possibilities for now operationalizing and then modeling aspects of melodic dictation are as advanced as they ever have been. Given that we can now assign numbers to basically every factor that is thought to contribute to this process from concepts of musicianship, to features of a melody, to the variable size in an individual’s working memory capacity all of these thigns can be put into some sort of model. While this will bring the community closer to formally modeling all of this and lead to a clearer understanding, before going ahead and doing this it is worth pointing out that many of the concepts discussed above are highly complex concepts like musicianship and tonalness and rest on lots of assumptions. Musicianship, for example, or any measure of musical training is not something that can be measured directly such as a person’s height or weight, but has to be inferred based on the logical assumptions of the person doing the measurments. So while the rest of this study will rely on this, it is important to note that people shouldn’t confuse abstracted concepts with real things. The most illustrative example of this comes from a study by HARRISON ET AL who created a latent variable model of aural skills that was able to predict 74% of the variance in aural skills performance. This latent trait that the authors created may be helpful in explaining the patterns of covariance in data, but this would be to reifiy a statistical abstraction as an ontologically true idea. This idea has been discussed before critqiuing ideas such as g (Gould 1996; Kovacs and Conway 2016) and has recently been the subject of critique in music psychology OUR GOLDMSI PAPER. The same arguments put forward in this literature also are relevant here. In order to have a complete, causal model of how melodic dictation works, it is important to understand melodic dictation as a set of musical abilities that are related to other musical abilities, though may not be related. This idea is not new even in music psychology, the past two decades have seen calls for a more polymorphic definition of musical ability (Levitin 2012; Peretz and Coltheart 2003) which in its modeling will require more concrete ways of defining how it works than just correlating variable together that are helpful at prediction without saying exactly how that process happens. 2.5 Conclusions In this chapter I first described what is melodic dictation using Karpinki’s verbal model, noted what the things were that were missing from this model as a stepping off point, then went on to suggest a taxonomy of these based on what already has done. I suggest there are both individual as well as musical features that need to be understood in order to have a comprensive understanding of melodic dictation. Of the two sets of features, individual features can be either cognitive or environmental and musical features can be either structural or experimental. This taxonomy does not consist of exclusive categories and certainly permits interactions between any and all of the levels. It would be impossible given the scope of this study to effectively quantify each and every factor and how it interacts at every level, but the degree to which there is the most literature and you can get the most bang for you buck seems like the obvious stepping off point. Rest of this dissertation will systehsize these areas and put forth novel research contributing to the modeling and subsequent understanding of melodic dictation. Understanding melodic dictation will help with both understanding melodic perception and help our pedagogy. 2.5.1 Add In (???) Dowling 1991 (Dowling 1991) References "],
["history-of-aural-skills.html", "Chapter 3 History of Aural Skills 3.1 Thesis: Show that aural skills always has practical end, efficacy of representation of musical pitch 3.2 Quotes from Schumann 3.3 Carl Seashore thinking in music 3.4 Points from Karpinski on pedagogy 3.5 Points from Royal Paper on pedagogy 3.6 Solmization System 3.7 Really this is all question of efficacy of mental representation of musical pitch", " Chapter 3 History of Aural Skills 3.1 Thesis: Show that aural skills always has practical end, efficacy of representation of musical pitch 3.1.1 for i in star aural people do 3.1.2 Who 3.1.3 Where 3.1.4 When 3.1.5 What 3.1.6 How (approach and goals) 3.1.7 Why 3.1.8 Guido d’Arezzo 3.1.9 Walerant (via Calvisius) 3.1.10 Banchieri 3.1.11 Cerratto 3.1.12 Penna 3.1.13 Zarlino 3.2 Quotes from Schumann 3.3 Carl Seashore thinking in music 3.4 Points from Karpinski on pedagogy 3.5 Points from Royal Paper on pedagogy 3.6 Solmization System 3.7 Really this is all question of efficacy of mental representation of musical pitch "],
["individual-differences.html", "Chapter 4 Individual Differences 4.1 Why care about cognitive abilities 4.2 Have established that cognitive abilities contribute to musical task (for journal article langauge repeat) 4.3 Remind the nature of a musical dictation type task (hear, loop, executive decision) 4.4 WMC has been misused in music education, theory, pedagogy, aural literature and deserves attention 4.5 Know WMC plays a role, sense, pertain, execute, should be able to pick up in experiment close to MD 4.6 Gold-MSI melodic Memory and beat perception test 4.7 IF we accept these DVs, THEN we should be able to predict them with self reports and measures of WMC and gf 4.8 Do this with hierarchical LVM ala Elliott paper 4.9 Overview of Experiment (cross sectional design)", " Chapter 4 Individual Differences 4.1 Why care about cognitive abilities 4.1.1 General intelligence and WMC 4.1.2 Defining of terms 4.2 Have established that cognitive abilities contribute to musical task (for journal article langauge repeat) 4.2.1 General Fluid Intelligence, WMC, Training as uni of polymorphic 4.3 Remind the nature of a musical dictation type task (hear, loop, executive decision) 4.3.1 This is WMC task, gf has problems (Although high level link with gf, problematic, WMC models at level of process of md) 4.3.1.1 Berz 1994 noticed it first 4.3.1.2 Williamson Baddely Hitch suggest maybe musical loop 4.3.1.3 Even Cowan labs wonder how different (Li Cowan Saults ) 4.4 WMC has been misused in music education, theory, pedagogy, aural literature and deserves attention 4.4.1 Problems with chunking 4.4.1.1 Mistake with Miller 1956, he did not mean 7 items 4.4.1.2 Broadbent 1956 more of why its more like 3-4 4.4.2 Problems with using capacity limit literature 4.4.2.1 See Cowan 2005 page 80 4.4.2.2 Musical order is always serial effects 4.4.3 Should be using Cowan model because of these things (zooming) or discuss within Baddely Hitch/Atkinson Shriff 4.4.4 One Note does not mean one unit in memory! 4.4.5 Confounded by corpus distributions 4.4.6 Lack of understanding (all aural skills are those that engage WMC, LVH says many students have WMC deficits, “increase memory”) 4.4.7 Point I am making is that if you’re going to do it, do it well. 4.5 Know WMC plays a role, sense, pertain, execute, should be able to pick up in experiment close to MD 4.6 Gold-MSI melodic Memory and beat perception test 4.6.1 What is gold MSI 4.6.2 What are issues I want to talk about with psychometrics 4.6.3 Describe test in detail and WHY it’s what we’re after here 4.6.3.1 not exactly mmd, but most people would say similar skill sets 4.6.3.2 also before getting dirty,need experimental desing with less response options (Cowan, Saults, Elliott, Moreano 2002) 4.7 IF we accept these DVs, THEN we should be able to predict them with self reports and measures of WMC and gf 4.8 Do this with hierarchical LVM ala Elliott paper 4.8.1 Versions of this paper at ICMPC 4.8.2 Exploratory in that tried a few different models (high type I error but whatever) 4.9 Overview of Experiment (cross sectional design) 4.9.1 Participants 4.9.2 Materials 4.9.3 Procedure 4.9.4 Results 4.9.4.1 Descriptive, Correlational 4.9.4.2 Modeling 4.9.5 Discussion 4.9.5.1 Review of the Goals 4.9.5.2 What were best model fits 4.9.5.3 Clear effect of WMC 4.9.5.4 What if we are just measuring WMC? 4.9.5.5 Obvs need this for futre studies 4.9.5.6 Need to use something to go above and beyond baseline (–transition to corpus as memory and n-gram) 4.9.5.7 Future verbal theoretical and computational models should involve capacity measures (limits) "],
["computation-chapter.html", "Chapter 5 Computation Chapter 5.1 Humans like patterns and are very good at picking them up 5.2 Pre-Musical Corpora 5.3 Musical Corpora 5.4 So What?", " Chapter 5 Computation Chapter OTHER PEOPLE WHO HAVE DONE THIS Folk music Bartok 1936? Bartok and Lord 1951 Lomax 1977 Steinbeck 1982 Jesser 1992 Sagrillo 1999 GET AND READ PAT SAVAGE ARTICLE Popular Music Moor 2006 Kramarz 2006 Furnes 2006 Riedemann ???? Computational Musicology Eerola eta al 2007 and 2007 McCay 2005 Huron 2006 Frieler 2008 JAZZOMAT PROJECRT OUTPUT 5.1 Humans like patterns and are very good at picking them up 5.1.1 We learn things implicitly 5.1.2 We can represent that implicit knowledge with a corpus 5.2 Pre-Musical Corpora 5.2.1 Information Theory 5.2.2 Computational Linguistics as front runner 5.3 Musical Corpora 5.3.1 History of Musical Corpora 5.3.1.1 Fun old computational music papers 5.3.1.2 Corpora that are often used 5.3.1.3 Static vs Dynamic models of feature abstraction (daniel slides?) 5.3.2 FANTASTIC 5.3.2.1 static 5.3.2.2 ML approach gets it right 5.3.2.3 simple to understand 5.3.2.4 Can abstract features be percieved? 5.3.2.4.0.1 Note density 5.3.2.4.0.2 Contour variation 5.3.2.4.0.3 Tonalness 5.3.2.4.0.4 weird computational measures 5.3.3 IDyOM as representation of musical materials 5.3.3.1 n-gram models 5.3.3.2 mirrors human behavior 5.3.3.2.0.1 melody 5.3.3.2.0.2 harmony 5.4 So What? 5.4.0.1 Other research (Chapt 3) suggest need to move beyond cognitive measures 5.4.0.2 Can operationalize item level items contextually with a corpus 5.4.0.3 IF features are real, they should effect dictation (Chater 6) 5.4.0.4 Not only important for one off, but then would be incorporated into computational learning models (Chapter 6) 5.4.0.5 We need new materials "],
["hello-corpus.html", "Chapter 6 Hello, Corpus 6.1 Brief review of Chapter 4 on corpus (Language to reflect journal submission) 6.2 Note problem with using corpus is making corpus 6.3 Solem duty to encode and report on corpus 6.4 The Corpus 6.5 Descriptive Stats of Corpus", " Chapter 6 Hello, Corpus 6.1 Brief review of Chapter 4 on corpus (Language to reflect journal submission) 6.1.1 Corpus outside of music 6.1.2 Corpus in Music 6.1.3 The point is that it implicitly represents humand knowledge 6.1.4 IDyOM 1 6.1.5 IDyOM 2 6.1.6 IDyOM 3 6.1.7 Huron suggestions that starts of melodies relate to mental rotaiton 6.1.8 Other Huron claims 6.2 Note problem with using corpus is making corpus 6.2.1 Many are used on Essen 6.2.2 Brinkman says Essen Sucks 6.2.3 If going to make generlizable claims, need to always have new data 6.3 Solem duty to encode and report on corpus 6.3.1 Justin London Article on what makes it into a corpsu 6.3.2 Though I just encoded the whole thing because in my heart of hearts I’m a Bayesian 6.4 The Corpus 6.4.1 History of Sight Singign books 6.4.2 Assumed to be where long term store comes from (adumbrate computational model) 6.4.3 Lots of melodies in ascending order of difficulty, grouped appropriately though? Utah guy 6.4.4 Why I encoded it in XML 6.4.5 Is it legal? 6.5 Descriptive Stats of Corpus 6.5.1 Why? 6.5.1.1 For pedagogical purposes 6.5.1.2 For experimental purposes 6.5.1.3 For computational idexing (get me melody with x tonal score) 6.5.1.4 Could serve as representation of implicitly learned expectations for future modeling 6.5.2 Feature Level 6.5.2.1 What features are normally distributed 6.5.2.2 Correlated feature problem 6.5.2.3 big ~facet wrap of the whole thing 6.5.2.4 Could do dimensonality reduction (Baker, Harrison, others) but then loose understanding 6.5.3 n-gram 6.5.3.1 Big solfege n-gram table 6.5.3.2 Dependent on representation (notes, solfege, mint) 6.5.3.3 Shiny app of n-gram heatmap with Peter 6.5.3.4 Idea would be that hotter n-grams lend them selves to better chunking (but need better word than chunking) "],
["experiments.html", "Chapter 7 Experiments 7.1 Rationale 7.2 Experiments 7.3 Computational Cognitive Model Model (If time permits) [Whole article in itself]", " Chapter 7 Experiments 7.1 Rationale 7.1.1 Have done all this and have not actually talked about dictation yet 7.1.2 Clearly many factors contribte to this whole thing and need to be taken into a model 7.1.3 Dictation is basically a within subjects design Experiment 7.1.3.1 Get very ecological and dirty and run it Paney 2016 had 30 second timing 7.1.4 Factors 7.1.4.1 Cognitive 7.1.4.1.1 WMC 7.1.4.1.2 GF 7.1.4.2 Training 7.1.4.2.1 Goldsmiths MSI 7.1.4.3 Musical 7.1.4.3.1 FANTASTIC 7.1.4.3.2 IDyOM 7.1.4.4 Investigate melodies with this context and set scoring 7.1.4.5 Mirror design to see if effects of melody are there 7.2 Experiments 7.2.1 Experiment I 7.2.1.1 Participants 7.2.1.2 Procedure 7.2.1.3 Materials 7.2.1.4 Scoring 7.2.1.5 Results 7.2.1.6 Modeling 7.2.1.7 Discussion 7.2.2 Experiment II 7.2.2.1 Participants (New) 7.2.2.2 Procedure (Same) 7.2.2.3 Materials (Swapped but controlled) 7.2.2.4 Scoring (Same) 7.2.2.5 Results 7.2.2.6 Modeling (same) 7.2.3 General Discussion 7.2.3.1 What happened 7.2.3.2 Assumption of all of this is that many things are happening linearly in combination with each other 7.2.3.3 Additionally the mixed effects framework works better with more data? 7.2.3.4 Also how we score it is going to mess wiht the DVs 7.2.4 Really what is needed is Computational Model 7.3 Computational Cognitive Model Model (If time permits) [Whole article in itself] COMPUTATIONAL MODEL So thinking all about this, first reviewing the literature and then trying to run experiments to figure it all out, got kind of frustrated because even with a mixed effects model, all it is saying is that as note density goes UP so does difficult, and it interacts with tonality. Def setting myself up for a “I could have told you that” moment from my music theory colleagues. Also figured since I am doing a dissertation called modeling melodic dictation, would be good to actually make an explanatory model of it. Hopefully by this point, have a good idea of the factors that might contribute, my task here was to then try and operationalize everything and make a computer do it. Actually really inspired by this Lewandowsky book where they had a quip about how wit the Baddeley model it really has like 150 permutations of it and some famous example of someone saying that men have more one night stands than women, but in a heterosexual population that is mathematically impossible. So it only seemed like it made sense to see if I could write one out. So this is how I think it would work, currently in the process of coding it. So essentially it’s a bayesian inspired model that compares a target melody, with a corpus of melodies or the prior, that are meant to represent all “known” musical material in someone’s musical understanding. I got the idea from reading about Cowan’s Embedded process model which does not posit the working memory structure as very distinct from that of everything in long term representation, but rather uses the central executive idea as the limited window of attention that can then be focused on things either in LTM or near categorical features of what is in the purveiw of attention. Will first go through it on a high level, then make another pass and talk about how everything is getting operationalised. So imagine that we have a prior corpus of all the melodies that are covered for sight singing and dictaiton in the first semester of aural skills (in this case, melodies X–XX). If we let the corpus M represent all prior knowledge, where not only is the melody represented as a string of intervals, but we also get ever n gram permutation of of the melody based on the idea that the more frequent the exposure of an n-gram, the more likely it would be to be understood. This is the first big parameter M. We could imagine and visualize this as a grid of distributions of all possible n-grams and the strings that make them up seen here GGPLOT2. Now although any string of notes is possible, in order to mirror the limited capacity of WMC, there needs to be some sort of threshold that is set that would mirror the limits of the window of WMC. This threshold is the next big parameter, T. Currently conceptualizing this as being reflective of maximum of information content threshold as calculated by IDyOM. Idea here is that as you hear more notes, more IC, the more your fixed capacity bin of melody is going to be filled up. By making it based on the IC of a melody string represented in the corpus, patterns that are more frequent are going to easier to then dictate, which aligns with intuitions on melodic dictation. Also need to define a the explicit, implicit threshold. Explicitly known n-grams should have some sort of fixed amount that if it succedes that, you would know it. Like karpinski “knowing” phase, would also assume that every interval class would also be “known” and if not, that is OK too, will lead to people not being able to transcribe it. We’ve now defined both the individual knowledge parameters and teh thrshold T of working memory capacity. These consist of WHAT DO YOU CALL THIS. With these individual parameters established, we can calculate difficulty of the melody by running what I am going to be determining as the ‘transcribe’ function, which is separate from the individual parameters. We then can introduce the target melody , t which represents the string to be dictated. Idea here is that this melody is compared to the corpus, M, and you get the IC of each of the n-grams from the prior corpus. Given the theshold, take the biggest n-gram that fits below the threshold to be put in the buffer. If you had a huge threshold and could take IC of whole melody or you KNEW it, would be reflective here. Could also introduce a function here that just gueses at about the threshold. Once this is filled up, let’s say 4 notes, the notes are then set to the transcription buffer. At this point index the n-gram is cross checked against the prior knowledge and look for matches of it that happen above a certain “known” threshold. If it is known, it gets “notated’ and you re-enter the melody. If not, in this case the 4 gram would get recursively truncated until found a string, even 2 gram where it is known. If it gets to a 2 gram and it’s not explicitly known, basically because you don’t know that interval, what Karpinksi rails againt as atomistic hearing. Also good in that people with bigger chunking will do better. If there is not an exact match, move to split fuzzy searches (future versions) Re-entry function is defined by finding the next part of the melody where either next most common n-gram occurs or where it left off last. This is then to reflect the two different ways of approaching tacking. Seing as some people start at front, others start at end. Could be reflective of primacy and recencey effects of memory, OR maybe it’s due to fact that more prototypical n-grams in habit starts and ends of melodies….? This process would then re-occur a few times over until either can’t go anymore (intervals are not known) or till completion. Afterwards have an idea of the path that it took, counts of those, use those as proxies of difficulty. I think this covers everything in the decision making process and each step of the process can be automated eventually (post doc anyone?!). More importantly, it reflects ecological phenomonologcial experience of taking melodic dictaiton. Aligns with intuitions that People who know more melodies will be better (singer phenomena) People will try for bigger chunks first, then go to smaller ones Atomistic transcription can happen but is inefficient People with higher chunking ability will do better IC is helpful proxy for this in line with IDyOM literature Relative pitch is where it’s at for things like this What’s deal with AP? 7.3.1 Why? 7.3.1.0.1 Better than verbal models 7.3.1.0.2 Sometimes even mathematically infesable proposed theory 7.3.1.0.3 Beyond Karpinski in that it doesn’t just schematize, says exactly when each thing is happening when 7.3.1.0.4 Lends itself to better discussions that don’t just rely on personal anecdotes 7.3.1.0.5 Can tweak the parameters 7.3.1.0.6 Can collect different types of data (corpus or experimental) and use the model 7.3.1.0.7 This model suggests that atomism approach is actual just subprocess of larger pattern 7.3.1.1 Theoretical Justification 7.3.1.1.1 Marries literature on LTM and prior knowledge, information theory, WMC, computation, representation 7.3.1.1.2 Also can be implemented in computer 7.3.1.1.3 represntation of rhythm too? 7.3.1.1.4 inspired by people like margulis 2005, albrecht and shanahan key finding, want something to contribute 7.3.1.1.5 Really Made me think 7.3.1.2 The Model (note many parameters can be changed in R package) 7.3.1.3 Prior 7.3.1.3.0.1 Corpus of music represented in form of n-grams 7.3.1.3.0.2 IDyOM extracts all possible n-gram permutations as learned corpus 7.3.1.3.1 Music notation fed into processing window where incoming n-gram is matched based on WMC window OR IT maximum 7.3.1.3.1.1 Information builds until approaches critical threhold 7.3.1.3.1.2 Upon maximum, model puts n-gram into focus of attention (Cowan 1988) and note why this is better than Baddely Hitch 7.3.1.3.1.3 Recursive transcribe function looks for LTM matches 7.3.1.3.1.3.1 Option 1: Pattern Matched and Pattern Transcribed, success? 7.3.1.3.1.3.2 Option 2: Pattern not matched in full, truncated and use match option again (should be higher probability of match with corpus) 7.3.1.3.1.3.3 Option 3: Pattern not matched downsize again until at interval level and relying on 2-gram (atomism) 7.3.1.3.1.3.4 On sucess of option, reopen gate at nearest long implicit n-gram LTM Match (start or end problem) 7.3.1.3.1.4 Put time contraints on search features 7.3.1.3.1.5 Transcribe process resets with trace image of melody after each dictation 7.3.1.3.1.6 Transcribe process ends when all notes accounted for 7.3.1.4 Model Output 7.3.1.4.1 Based on leanrning, times needed to hear it 7.3.1.4.2 Completion percentage 7.3.1.4.3 Rank order of easier to transcribe parts based on learning 7.3.1.5 Model Compared to Data 7.3.1.5.1 With Experimental Data 7.3.2 Future Suggestions for Aural Skills Pedagoges and Research 7.3.2.1 Use model as teaching stepping off point 7.3.2.2 Should move towards LTM pattern matching 7.3.2.3 Reason that people learn how to sight sing is to INCREASE the learning of the implict corpus 7.3.2.4 Circular process here 7.3.2.5 Is this what it means to then think IN music 7.3.2.6 Really it’s to just know the patterns maybe like model where Justin London suggests we get to know patterns and expect themn 7.3.2.7 Would also make sense in terms of Leonard Meyer 1956 7.3.2.8 Use WMC in music theory, cognition, education studies "],
["reference-log.html", "Chapter 8 Reference Log 8.1 To Incorporate 8.2 Chapter 3", " Chapter 8 Reference Log 8.1 To Incorporate (Margulis 2005) – Margulis Model (Nichols, Wöllner, and Halpern 2018) – Specialty jazz background helps in tasks, WMC (???) – Fix intext (Schumann and Klauser 1860) – Quote about why people should do ear training (Smith 1934) – Quote from K2001 about why people should do ear training (Long 1977) – Musical Characteristics predict memory (Taylor and Pembrook 1983) – Great citation that lots of things change memory, even structural! (???) – Long boring talk on STM, LTM (Oura 1991) – Awful experimental design that says people use structual tones (Buonviri 2014) – Call for experimental, suggestions as to what factors might contribute, use of deductive reasoning, qualitative (Buonviri 2015) – People need to focus right away, not establish, distractors (N. Buonviri 2015) – Showing people visual music does not help much. (Buonviri 2017) – Listening helps with other things, no best strategy in terms of writing (N. O. Buonviri and Paney 2015) – Literature to say people are bad at teaching melodic dictation and we don’t know a lot about it, also interesting stuff about what solfege systems people use (Butler 1997) – Call for music educators to do aural skills research, notes problem with aural skills pedagogy in lack of direction, also nice Nicholas Cook quotes on point of theory (Furby 2016) – music ed study with weird stats, has references to follow up on with advantages of pitch systems and people who reccomend things for sight singing (Pembrook 1986) – Effects of melodies, also how people do it. Interesting that they too effect of melodies, but talka bout things in terms of notes and not in terms of information content. Thought ot have an experiment where the n-grams that are more common are easier to write down. Lots of good charts too. (Paney 2016) – It’s not good if you tell people what to do when they are dictating, article has a lot of good review for dictation materials to add to the ‘toRead’ folder. (Fournier et al. 2017) – Good references that people are awful at Aural Skills, Also suggestions that people are not that great at transfer, and some stuff to suggest academic abililty is intertwined in all of this. Good reference for when starting to talk about untangling the mess that is aural skills. (???) – Add on a new module to the WMC model of baddel with music, presents some evidence for why this theoretically should be included, but actually takes examples of dictation. A lot of this article felt like things that i was reinventing…not good. (???) – Proof some other people are starting to think in terms of pedagogical schemas (Klonoski 2000) – Music cognition needs to talk to aural skills more, also need to unbind theory routine with aural skills and think of things more as in a perceptual learning hierarchy (Klonoski 2006) – great quotes that when people get something wrong with aural skills, what does that even mean, lack of transfer effects, article ends with ways to get better at things (Pembrook and Riggins 1990) – Survey of what people in the late 1980s were doing in terms of aural skills pedagogy (???) – addresses why Gary Karpinski thinks we should teach melodic dictation (Potter 1990) – dictation teacher surprised that people don’t keep up their dictaiton skills quote 8.2 Chapter 3 (Cowan 2005) – This book will probably serve as cornerstone of chapter in terms of creating relevant literature in addition to EE course readings on WMC. Provides history of WMC models and notes how attention based model as opposed to Baddely loop might actually be better theoretical model for talking about fact that WMC could just be something related to attention if not that. Provides extensive listing on problems with chunking that are all relevant to music, but then also supports it. Shows that Miller 1956 is a generally bad citation, own author even says that in Miller 1989 (check and add) and says limit is probably about 4 (use Cowan 2001 for ctation find that). Lots of good ideas like how music is always serial recall, examples of how to model the process, great discussions on zooming out and categorical nature of music within span of WMC ideas. (Ockelford 2007) – uses case of savant to argue bits of Berz WM Music Model References "],
["references.html", "References", " References "]
]
