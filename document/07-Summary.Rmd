# Summary

Melodic dictation is a cognitively demanding process that requires individuals to be able to hear a melody then write it down.
Not only is understanding how this process works worthy of study from a pedagogical perspective, but the ability able to hear, understand, then notate a melody is a fascinating psychological feat.
Complex sound waves cause the tympanic membrane to vibrate, these vibrations are transmuted from physical to electrical energy in the brain, then this incoming sensory signal is organized via top-down processing for our inner homunculus to decipher and translate these hierarchically organized sensations into meaningful symbols.
Understanding the intricacies of this process is a complex problem, but complexity is what initially attracts many people to music in the first place.
By dissecting each part of this listening process, it is possible to gain more and more understanding of music. 

In this dissertation, I began by examining the Karpinski model of melodic dictation.
While fantastic as a didactic model, the model is not specific enough to be examined with both experimental and computational methodologies.
The model is idealized and was originally developed for pedagogical, rather than explanatory purposes.
It assumes similar processes for different individuals and extends these assumptions to different melodies.

Using these assumptions as a point of departure, I put forward a taxonomy of features that could be used to fill the voids in the Karpinski model were it to be adopted for research purposes.
The taxonomy posits that both individual and musical factors will contribute to an individual's performance on a musical memory task.
Individual factors include cognitive and environmental factors; musical factors include structural and experimental factors.
While I used this taxonomy as a guide in my literature review, the taxonomy can also aid in organizing future research on musical memory.
The subsequent chapters of this dissertation explored the factors of this taxonomy.

In the third chapter, I demonstrated how differences in individual ability can be accounted for in melodic dictation in both musically trained and untrained individuals.
I put forward evidence to corroborate claims by @berzWorkingMemoryMusic1995 and stressed the importance of including cognitive ability as a measure of interest when considering musical memory.
Understanding these factors is important because we as aural skills practitioners and pedagogues need to be able to know if the degree of a student's ability to complete a task is within their ability to change it.
If this skill is malleable, we need to understand how to best cultivate it.
If a skill is not malleable, we need to take caution not to design assessments that measure something beyond the student's control.

In the fourth chapter, I posited that tools from computational musicology can help better understand the musical side of the taxonomy.
I used a survey of 40 aural skills pedagogues to demonstrate the degree of agreement between what makes melodies difficult to dictate.
Using this survey data as a ground truth, I then showed how various computational measures can then be mapped to human judgments of difficulty.
Surveying the application of these computational methods to expert data allowed me to highlight the benefits and pitfalls of using various types of computations.
Measures inspired by information content captured large amounts of the variance of the expert data. 
This lead to an assertion of how tools from computational musicology can act as a bridge to formalize ideas put forward by cognitive psychology.
Considering this, I put forward a novel theory of musical memory: the Frequency Facilitation Hypothesis. 
I showed how combining both computational measures with theories from cognitive psychology can help better understand the difficulty of the tasks we ask of students.
The chapter concluded by putting forward meaningful ways in which these ideas might be used to create a more linear path to success in the aural skills classroom.

In the fifth chapter, I presented the _MeloSol_ corpus.
This corpus is a collection of 783 monophonic vocal melodies taken from a standard sight singing textbook [@berkowitzNewApproachSight2011].
The _MeloSol_ corpus is not only a contribution for future research in music perception, music pedagogy, and computational musicology, but in introducing the corpus via a corpus analysis, I was able to highlight many addressed assumptions in computational musicology. 

In the sixth chapter, I modeled how melodic dictation could be operationalized using an experiment that takes full advantage of robust statistical modeling techniques.
When cast as an experiment, the amount of variables at play in melodic dictation is cumbersome from both an individual and musical point of view.
By utilizing methods from computational linguistics that have already been developed to ameliorate these problems, I put forward a more stable and robust framework that future experiments investigating melodic dictation can implement.
Using a more consistent, flexible framework will allow for more interpretability across studies and bring more cohesion to future literature examining melodic dictation.

Lastly, I introduced a cognitive, computational model of melodic dictation.
This model allowed me to formalize all the theoretical factors deemed relevant to melodic dictation and incorporate them into a computational model.
Not only does creating a computational model declare all ontological assumptions, but introducing this closed system allows for future systematic investigations to the model's verisimilitude.
The model makes several falsifiable predictions that can be investigated in future research.

There is still plenty of research to be done in terms of bridging the gap between the world of aural skills pedagogy and music psychology, but within this chasm is a large potential for knowledge.
Research at this intersection is important for aural skills pedagogues, as it helps hone our understanding of how to be effective classroom teachers.
Research at this intersection is important for music psychologists, as questions of music perception are able to provide novel insights into cognition that might only be accessible through the complex phenomena which is music.
Understanding the building blocks of aural skills is understanding the building blocks of musical perception. 
The two go hand in hand.

\cleardoublepage
