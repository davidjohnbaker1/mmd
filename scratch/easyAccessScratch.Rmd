---
title: "ScratchMaterial"
author: "David John Baker"
date: "August 29, 2018"
output: html_document
---

Is there soemthing to be said about the change point access for when there is reentry of the transcription function

## Chapter 1

The sequence of steps occurs for each chunk of music that is extracted during dictation and in the case of TABLE X, happens twice.
In his text, Karpinski presumes this process could happen with a melody that can be extracted in two parts, which according to his prescribed formulas^[In the third chapter of _Aural Skills Acquisition_, Karpinski suggests that the number of playings should be calculated based on the formula FORMULA, where DEFINE WHAT HE SAYS] would consist of a melody from twelve to twenty notes long for listeners with few or no chunking abilities. 
As stated above, reviewing the Karpinksi four step model will establish the current state of thinking on melodic dictation and thus create a groundwork from which this current study will build.

One could even go further and borrow a thought experiment from the world of neuroscience and imagine a double dissociation with melodic dictation ability and musical skill.
Thinking about one's colleagues 

Even using a simple thought experiment using the old double dissicoation thign that htey love in neuroscience where you could imagine both situations where someone was probably a very good musician, but not that great at melodic dictation, or the converse where someone might be very good at melodic dictation, but is not that good of a musician (whatever that means) would indicate that there is probably not that strong of a casusal link between dictation abilities as measured by grades in an aural skills class and the infinite possiblities of musical activities that are even possible.  

This similarity between studies should still be interpreted in light of other research that argued against a need for higher working memory functionality in expert level performances (e.g., HOWE,DAVIDSON, & SLOBODA, 1998). 


In her textbook _Practical Ear Training_ Janet McLoud McGaughy notes that

> qualified musicians must develop reading, singing, and notational skills in order to achieve acuity of aural perception and to make effective use of that acuity" (p. i)."

which makes the point that the development of ear training is about developing acuity in aural percepiton which then is then transfered over for other musical activity.
In his forthcoming article in the Journal of Music Theory Pedgagogy, UTAH MAN SAYS.....

UTAH MAN SAYS IT BEST WHEN HE SAYS 

UTAH MAN QUOTE

#### Verbal model, has problems, OK for pedagogy

As a verbal model, Karpinski's model of dictation makes sense and breaks down a very complicated cognitive process into discrete, sequential steps.
This model, whether or not Karpinski intented it to be an actual cognitive model, I don't know, assumes serial processing of information and does not specify any of the actual parameters for each of the steps.
This model serves as a great stepping off point for this dissertation, and its good for me that he didn't actually specificy any of the actual parameters, he just said certain things happen and gave an approximate order of the whole thing.
He talks about a lot of the parameters leading up to it all,
Even talks about things like representation and other paramters that are going to influence it all.
Did not attempt to pin down any of the exact parameters of his model, but this is just me wanting to forshadown Chapter 6 where I take each of these issues and implement them in a computational model. 
While covering many bases, one of the problems with using a verbal model as opposed to a computational one is that by not specificying exaclty what happens when and how everything is represented, the model can manifest itself in a multiude of different ways.

Take for example the often cited model of working memory by Alan Baddely and Grahm Hitch which posits a modular view of workign memory capcacity [@baddeleyWorkingMemory1974].
As discussed in CITE, although the model only has X amount of distinctive systems, the fact that they left it to be a verbal model of memory, and did not tack down exactly how each parameter functions, when built as computational model actually ends up yielding 156 different models. 
While I will reseve discussing how many possible models might exists as derrived from the Karpinski for Chapter 6, it is suffice to say that clearly establishing the degree to which part of the model contributes in concrete way only helps with furthering the literature.

When viewed from a pedagogical stand point, espcielaly given how litle time people have, it would basically be impossible to attend to each of these things in a gradient fashion in the standard 15 week semester that people have. 
When people teach this, need to rely very much on intuition and basically adjust to the level of your class and syllabus and whatever on the fly in order to convey the most amount of musical materials possible. 

Conversly, when viewed from an experimental standpoint, each of the above mentioned processes is bascially an experimental parameter waiting to be investigated.
Additionally, the process that is put forth by KARPINSKI 1999 provides a stepping off point for positing some sort of comutational model.
Going to add substatinally to it in that going to take into account both how difficulty the melodies are, something we have intiutive understanding of, but could be operationalized, and also going to try to model individual differences based on factors that prior literature would suggest are different in individuals and should be considered in any sort of modeling going forward. 
In addition to these above parameters discussed by Karpinski, now review other factors that could then contribute to this process.

Clearly, would be worth understanding the concept at a deeper level since clealry they have done a lot of great work on the topic. 
Adoptiong chrnological take of the history of research the heavy hitters are 
* Attkinson and Shriff 
* Miller 1956 and why that is a bad idea
* Baddely and Hitch 
* Nelson Cowan + need for complex span

For reasons discussed on p 18 of cowan 2005 and page 42 , choose to adopot a Cowanian view where WMC is basically the window of attention.
Additinally it's worth noting initially that you can't directly apply these frameworks to memory for musical material because after reading page 109 in Cowan, important to note that all melodies appear in serial order. 
To make analogous task based on something like complex span tasks, would need to take certain set of notes and then always a finate setb be played back in arandom order (see chatper 3)

## Old Drafts of Chapter Structure BELOW THIS LINE 
## Theoretical Background and Rationale

As stated above, melodic dictation is a hugely complex process.


What am I going to do in this chapter?
  + Intro to aural skills and melodic dictation 
  + Talk about the factors that go into it (basically real time suduko)
    + Cognitive
    + Musical 
  + Note that reserach is messy, need to think of it polymorphically
 

Even anecdoatal evidence suggests that people who are good at this tend to stay good and people who are bad at it tend to stay bad

Other things that I might not want to bring up right now is that a lot of this could just be thought of as relating to a big thought experiemnt where you could imagine that there are many musicians from lots of different muscial cultures (bring in the ethnos!) that could imagine being sucessful at what they do without having this ability to take melodic dicatation.
Is it just a party trick? 
Also here would be a good place to jump off of and talk about the lack of transfer.

Where do people learn it? -- Music school
Part of large thing of aural skills 
Absoulte ubiquity, but for the amount that it is done, relatively understudied

   

Not only is this process intenstive, but also ubiquitous 

## 

@karpinskiAuralSkillsAcquisition2000 schematizes this ability into a four step process of hear, remember, understand, notate (See Figure 1?).

While 
Some researchers have estimated that XX amount of processes are needed to sucessfully execute this task FIND CITATION. 

-- Should be drawing here from ICMPC paper?

## Order of Chapter 1

* Hook on why this is important
* What is melodic dictation?
  + Process (reasons of why factors)
  + Who has talked about it before?
  + Why is it important -- training ear and transfer
* Most of the people who are talking about this are pedagogical, really it's perceptual 
* Here is huge list of literature of things that might contribute
  + Pedagogical factors
  + Cognitive Factors
  + Musical Factors 
  + All of these are moving parts, need better tools to describe
* While this is the narrative, does not conform to updated view of polymorphism of musicianship

## Order of Chapter 2

HOLDER 

### General intelligence and WMC 

* His rationale was that he thinks there was a musical loop in the context of modular models of wmc ala baddely 
* Not nessecarily the case since there are other theoretical frameworks to talk about music 
* As stated above, looking at music provides a unique insight into contributing to discussions of wmc

### Defining of terms

* Having established this is a good problem, time to talk about what I think these terms mean
* This is what gf is 
* These are the people that have studied it and what they have found 
* This is what wmc is as defined by Cowan 
* Again, very clear parallels to wmc and if we can answer them w good evidence on large scale, good reason to think otherwise small
* We see that in this.... literature
* Could it be that there is a musical loop here ala Berz, Williamson, and would that explain Li Cowan Saults?

* See, it's a great qustion to investigate 
* Tho one big problem with music is that it's a lot harrier than other stimuli 
* Every problem with chunking that Cowan 2005 talks about could be applied to music
* Cant assume one note means one unit of memory and so on 
* On top of that you have Pearce suggestion that things are encoded differently 
* Also have problems of corpus distributions similar to words, good evidence for SLR and PPH 

* regardless of this hariness, need to get further into it
* Okada and slevec show that EF is also really important to make picture clearer
* tho if you really want to to do working memory capacity, need to do complex span
* the reason for this is xyz, can continue on from there
* Again, WMC is underlying a lot of music stuff, we should see it on large scale 

* Start setting up hypotheses 
* What best predicts someone's ability to do well on a musical memory test? 
* Not going to go straight to melodic dictation, first look into Berz 
* If it really is musical training, we should be able to see that using measures of musical survey
* If it's actually some sort of cognitive process, then that should have more predictive ability 
* We can figure this out by fitting a series of models to the data and seeing which matches up best and it's measurements
* Great ensemble of tests is the Gold-MSI bc it has self report and objective, and people have replicated it 
* Specifically there are two objective tests
* Describe them here
* not exactly mmd, but similr skill set 
* IF we accept these DVs, THEN we should be able to predict them with self reports and measures of WMC and gf
* Do this with hierarchical LVM ala Elliott paper 

* List hypotheses and predictions


Two questions here 

* Was Berz 1995 correct in asserting that there is a musical loop using the modular view of WM? 
* To address this, need to talk about modular vs domain general models 
* And music is great to look into this because maybe it would act differently than words
* Also you can manipulate different kinds of musical material which would help out 

Questiosn to be answered in this chapter 
* Is, as berz said, WM something very important for music perception literature, are we just measuring that?
* Can address this by doing a series of structrual equation models that see how things are predictive
* Also would assume that you could see statistically identical measurments for evidence that they are the same. 

Conclusions to be drawn 

* Yes, WM is important, especially at the higher level
* Are there span differences responsible for any predictive things?
* How does this differ from gf intelligence 
* Can you fit this at all in with process overlap theory? 


* Most of this literature comes from pedagogy
* All quotes about people should be able to do this
* Long history of Aural Skills 
  + Older people
  + Current Methods
  + Their goals 
  + Their assumptions 

+ People are not good at this 
  + Wennerstronm (1989) said people at IU are not good at aural skills and sight singing p.163 (k7)
  + Julliard (1953,p. 48) incoming students have untrained ear (k7)
  
+ nice quote from chittum 1967 "the da is past when teachers can say, you either have it or you don't" (p.73)
+ Start of a big Journey back then, even more now (almost 2 decades since Karpinski, 2000)
 
 
### Theoretical Background

Lots of older studies looking at this listed on page 2 of Taylor and Pembrook 1983 (List here)

#### Computational Musicology 

#### Music Psychology and Memory for Melody

### Rationale 

#### Computational Musicology

#### Music Psychology 

### Factors

This section will list factors that are believed to be important to modeling melodic dictation.
Need to have both individual and musical parameters.
Ends with polymorphic view of musicianship.
  + Nichols, Wolner, Halpern 2018
  + Niels paper on Jazz similarity
  + My paper on Wagner 


+++++++++++++
Pitch in Karpinki 

+ Pitch Matching (Work being done with Seatle, Pfordresher)
+ Pitch Memory (See Snyder)
+ Pitch Collection and Chunking 
+ Infereing Tonic
+ Melodic Contour 
+ Scale Degrees 
+ Identification of Intervals
+ Identifcaiton of Scale Types 
+ Solimization Systems 
+ AP

+++++++++++++++++++
Melodic Dictation 

Kraft 1999 -- First part of book is for melodic dictation
Benward and Lolosick 1996a -- Melodic Dictation

Karpinski 1990 Has its own model for melodic perception?? 

Page 66 of K -- Relevant Melodic Contour Information 
page 68 of K -- Deutsch -- Familiar systems are better (now we have IDyOM)
Dowling and Harwood 1986 124-44 Melodic expectancy (probably better for Pearce)
READ Sloboda and Parker 1985

THURSDAY FOLLOW UP!
Follow Ups of Note Max 
  + Tallarico 1974
  + Long 1977
  + Pembrook 1983
  
7-11 Notes? 
Marple ND reports that most things land in 7 +/-2, But not mention of IC! 
Found that if you make it rhythmic, goes up to 6-10, rhythm helps, but maybe it's just shorter time

Potter 1980 -- most people chunk (obvs question of segmentation)
Deutsch 1980 rhtym alines with pich, people do better than non-hierarchy 
Oura 1991 -- MODEL OF HOW MANY PITCHES PEOPLE REMEMBER, use for corpus question on pattern matching

Hofsetter 1981 -- people do better in bottom 4 time than 8 (again maybe confounded by IC)

Page 98 in Karpinksi has lenght and number of playings, 

Effect of tempo in  Unks, Bowers, and Eagle 1993

figure 3.1 is Karpinski method to understand dictation process



+++++++++++++++
Define the rationale and significance for this study
talk about what the processes are that go into this 
What are the implicit transfer claims of this? 
    + discussed in chapter 2 (history and rationale, Karpinski)
    + transfer literature also dicussed in chapter 2
Is there literature specifically on this? Yes, but scant.


what contributes to this whole process?

Note that there are two fields, both of which's literature can help out.


===================
63 words at start 

## Chapter 2

## First Establish Others think this is Important 

### Historical Evidence 

### Current Evidence 

## Solimization

### What is Solimization 

### Brief History of it 

## Current State of Aural Skills

+ Guy that just wrote that dissertation on it in England 


History of Aural Skills a lot from other sources
  + Karpinski (Schumann, Smith, Benward and Car, Benward and Kolosick, Butler 1997)
  + Wolf and Colleagues
  + Best-- thinking 'in' music 1992
  + Serafine 1988 thinking in or with sound / 
  + Elliott 1996 thinking about music without 'understanding'
  === These all really just have to do with mental representation? 
  
  Karpinski -- "Music listeners who understaqnd what htey hear are thinking in music" <-- claim page 4
    + could imagine a thought experiment where understanding implicit and explicit knowledge of this

Karpinski notes that (Butler and Lochstampfor, 1993) no link between pedagogy and music cognition.


## Old Farts To Talk About 

- Guido of Arezzo
- Gioseffo Zarlino 
- Franchinus Gaffurius
- C.P.E. Bach
- Jean-Philippe Rameou
- Arnold Schoenberg
- Heinrich Schenker 

- Adriano Banchieri <-- first to fix guido's hexachord 
- Hubert Walerant (via Calvisius)

- Timothy Johnson's Article on solimization 
- Gregory Barnett - cambridge guide, 17th Century Organization
- Lorenzo Penna 

  
* Compare and contrast goals in terms of pedagogy and teaching. 

## Current State 

* Books and what not. 

## Chapter 3
### Cognitive Aparatus

### Training Effects 

## Transfere Literature 

### Memory for Melodies Literature 

### WMC 

* Nichols, Wollner Halpern, 2018

### Gf 


###Outline Notes

* Melodic Dictation is clearly something that uses WM
* Also dependent on WMC
* Problem is that there is not a direct comparison
* WMC tasks, simple and complex are with novel stimuli
* Even in cases of WMC, need to control for word frequency
* This allows us to know that exposure effects this ability
* Huge amount of work on statistical exposure (Saffran, Huron, Margulis, Pearce)

* Could take theories of WMC but capacitity limits and WMC task do not medoel the sequential and hierarchical nature of melodies
* Obvious alternative to this is to look at n-grams in melodies
* Image chart where overlay of n-gram is reflected in frequency distribution of chart
* Clealry we have task where complex entertaining of information and working

* What is emlodic equivlient to the word length effect?
* Is there such a thing with decay and melodies (Lewandasky + Corey's work)
* Hard to model idea of repeating things bc of rhythm problem and temporal properties

* STOP IT WIHT THE MILLER (Articles that reference Miller but get it wrong list)

* Question of how is music represented, is there some sort of pholoogical representation (is then the point to split the intervals with each phonological rep with the episodic buffer playing a role?)
* Do students need to know what their WMC maximum is

### Cowan Reading Notes

* It's helpful to assume there are constants in psychology 
* Why prefer Cowan over Baddeley, boat example 
* Stop with the miller 7 quotes, should be listing of these
* WMC as form of attention
* History of WMC models (Process Model Attkinson, Baddely, Berz, Cowan)
* Rapid formation of new episodic buffer
* Is solfege assigment automatic? Transferred to new realm of representation
* Need to get away from idea of chunking for MMD
* Melodies are always in serial order 
* Aka from above need to look at n-gram representation
* could imagine making some sort of sensory memory experiemnt ala page 114
* More options to write down, more error on recall, clearly not free recall situation, pattern matching

- I want examples of frequency distribution confounding memory experiemnts

## Baker Model of Melodic Dictation (Over Karpinski)

* Divert attention to maximum n-gram 
  * Open n-gram/attn to LTM matching
  * When LTM match maxed, put n-gram in phological loop 
  * Transcribe all matched n-gram with LTM match ups (effecient processing? sd)
  
  - {Warning if beyond capacity limit} (tho how does this relate to LTM)
  * IF {Chunk is understandable => Transcribe}
  * IF {Chunk is not understandable --> Segment to smaller unit }
    * LTM as first option (contextualized)
    * Rhythmic and Contour framework 
      -- SD options first on contour
      -- Avoid Interval (last resort) requires LTM single interval pattern match with n-gram of loop
      -- Also avoid interval because it disgards maximum of n-gram
  * Only patterns with LTM match will be transcribed (aka do sight singing)
  * If not LTM match, then need recursive process to figure out new schema for looped n-gram
  
* Also, model that took n-gram funcitonality into the description would also account for weird atonal melodies where they have no function, but rather are built upon diatonic sequencs that are linked together with atonal gestures
      
* Theoretical reasons for stopping atomistic sight singing
  - It's only small block of more fluid and complex process
  - Could AP mapping be brought in here? 

* Span speed correlation and doing some sort of melody thing wiht an experiment 

* Eventually do POT and Music for this 

## Chapter 4
### Musical Parameters

#### Inspiration from Computational Linguistics 

#### Feature Extraction in Music 

##### Symbolic Approaches (Static)

##### Symbolic Appoaches (Dynamic)

##### Behavioral Results 

#### Point is that these features can stand in for intuition


## Chapter 5

### Why need new data 


### History of Corpus Studies 

### Current State in Music

### Limitations

### Boring Corpus Stuff

#### Encoding Process

#### Sampling Criteria

#### Situation of Corpus Methods

### Descriptives of the Corpus compared to Essen/Dutch/Whatever

## Chapter 6

### Rationale for Experiment

### Selection of Melodies

* Tonalness, Countour, Number of Pitches - Long 1997 Tonalness good predictor
* Tonalness better than atonal (Frances 1958) Zenatti 1969 -- from Long 1997
* Taylor 1977 -- IC predicts when contour and lenght constant 
* Long 1997 -- IC affects information 



### Experiment I and II

### Experiment III?

### Limitations

#### How to Score 

#### Reasons for making everything open source

### Summaries

#### Applications to Pedagoges

#### Conceptual Frameworks 

### Conclusions

#### What can we really expect of undergrads?


### Why?
##### Better than verbal models
##### Sometimes even mathematically infesable proposed theory
##### Beyond Karpinski in that it doesn't just schematize, says exactly when each thing is happening when
##### Lends itself to better discussions that don't just rely on personal anecdotes
##### Can tweak the parameters 
##### Can collect different types of data (corpus or experimental) and use the model
##### This model suggests that atomism approach is actual just subprocess of larger pattern 
#### Theoretical Justification
##### Marries literature on LTM and prior knowledge, information theory, WMC, computation, representation
##### Also can be implemented in computer
##### represntation of rhythm too?
##### inspired by people like margulis 2005, albrecht and shanahan key finding, want something to contribute
##### Really Made me think
#### The Model (note many parameters can be changed in R package)
#### Prior
###### Corpus of music represented in form of n-grams
###### IDyOM extracts all possible n-gram permutations as learned corpus
##### Music notation fed into processing window where incoming n-gram is matched based on WMC window OR IT maximum 
###### Information builds until approaches critical threhold 
###### Upon maximum, model puts n-gram into focus of attention (Cowan 1988) and note why this is better than Baddely Hitch
###### Recursive transcribe function looks for LTM matches 
####### Option 1: Pattern Matched and Pattern Transcribed, success?
####### Option 2: Pattern not matched in full, truncated and use match option again (should be higher probability of match with corpus)
####### Option 3: Pattern not matched downsize again until at interval level and relying on 2-gram (atomism)
####### On sucess of option, reopen gate at nearest long implicit n-gram LTM Match (start or end problem)
###### Put time contraints on search features 
###### Transcribe process resets with trace image of melody after each dictation 
###### Transcribe process ends when all notes accounted for 
#### Model Output
##### Based on leanrning, times needed to hear it
##### Completion percentage
##### Rank order of easier to transcribe parts based on learning
#### Model Compared to Data
##### With Experimental Data 
### Future Suggestions for Aural Skills Pedagoges and Research
#### Use model as teaching stepping off point
#### Should move towards LTM pattern matching
#### Reason that people learn how to sight sing is to INCREASE the learning of the implict corpus
#### Circular process here
#### Is this what it means to then think IN music
#### Really it's to just know the patterns maybe like model where Justin London suggests we get to know patterns and expect themn
#### Would also make sense in terms of Leonard Meyer 1956
#### Use WMC in music theory, cognition, education studies

--------------------------------


## Computational Cognitive Model Model (If time permits) [Whole article in itself]

COMPUTATIONAL MODEL


So thinking all about this, first reviewing the literature and then trying to run experiments to figure it all out, got kind of frustrated because even with a mixed effects model, all it is saying is that as note density goes UP so does difficult, and it interacts with tonality. Def setting myself up for a “I could have told you that” moment from my music theory colleagues. Also figured since I am doing a dissertation called modeling melodic dictation, would be good to actually make an explanatory model of it.

Hopefully by this point, have a good idea of the factors that might contribute, my task here was to then try and operationalize everything and make a computer do it.

Actually really inspired by this Lewandowsky book where they had a quip about how wit the Baddeley model it really has like 150 permutations of it and some famous example of someone saying that men have more one night stands than women, but in a heterosexual population that is mathematically impossible. So it only seemed like it made sense to see if I could write one out.

So this is how I think it would work, currently in the process of coding it.

So essentially it’s a bayesian inspired model that compares a target melody, with a corpus of melodies or the prior, that are meant to represent all “known” musical material in someone’s musical understanding. I got the idea from reading about Cowan’s Embedded process model which does not posit the working memory structure as very distinct from that of everything in long term representation, but rather uses the central executive idea as the limited window of attention that can then be focused on things either in LTM or near categorical features of what is in the purveiw of attention.

Will first go through it on a high level, then make another pass and talk about how everything is getting operationalised. So imagine that we have a prior corpus of all the melodies that are covered for sight singing and dictaiton in the first semester of aural skills (in this case, melodies X--XX). If we let the corpus M represent all prior knowledge, where not only is the melody represented as a string of intervals, but we also get ever n gram permutation of of the melody based on the idea that the more frequent the exposure of an n-gram, the more likely it would be to be understood. 

This is the first big parameter M.

We could imagine and visualize this as a grid of distributions of all possible n-grams and the strings that make them up seen here GGPLOT2. 
Now although any string of notes is possible, in order to mirror the limited capacity of WMC, there needs to be some sort of threshold that is set that would mirror the limits of the window of WMC.

This threshold is the next big parameter, T. 

Currently conceptualizing this as being reflective of maximum of information content threshold as calculated by IDyOM.

Idea here is that as you hear more notes, more IC, the more your fixed capacity bin of melody is going to be filled up. By making it based on the IC of a melody string represented in the corpus, patterns that are more frequent are going to easier to then dictate, which aligns with intuitions on melodic dictation.

Also need to define a the explicit, implicit threshold. Explicitly known n-grams should have some sort of fixed amount that if it succedes that, you would know it. Like karpinski “knowing” phase, would also assume that every interval class would also be “known” and if not, that is OK too, will lead to people not being able to transcribe it. 

We’ve now defined both the individual knowledge parameters and teh thrshold T of working memory capacity. These consist of WHAT DO YOU CALL THIS. 

With these individual parameters established, we can calculate difficulty of the melody by running what I am going to be determining as the ‘transcribe’ function, which is separate from the individual parameters. 

We then can introduce the target melody , t  which represents the string to be dictated.

Idea here is that this melody is compared to the corpus, M, and you get the IC of each of the n-grams from the prior corpus.

Given the theshold, take the biggest n-gram that fits below the threshold to be put in the buffer. If you had a huge threshold and could take IC of whole melody or you KNEW it, would be reflective here. Could also introduce a function here that just gueses at about the threshold. Once this is filled up, let’s say 4 notes, the notes are then set to the transcription buffer. 

At this point index the n-gram is cross checked against the prior knowledge and look for matches of it that happen above a certain “known” threshold. If it is known, it gets “notated’ and you re-enter the melody.  If not, in this case the 4 gram would get recursively truncated until found a string, even 2 gram where it is known. If it gets to a 2 gram and it’s not explicitly known, basically because you don’t know that interval, what Karpinksi rails againt as atomistic hearing. Also good in that people with bigger chunking will do better.

If there is not an exact match, move to split fuzzy searches (future versions) 

Re-entry function is defined by finding the next part of the melody where either next most common n-gram occurs or where it left off last. This is then to reflect the two different ways of approaching tacking. Seing as some people start at front, others start at end. Could be reflective of primacy and recencey effects of memory, OR maybe it’s due to fact that more prototypical n-grams in habit starts and ends of melodies….?

This process would then re-occur a few times over until either can’t go anymore (intervals are not known) or till completion.

Afterwards have an idea of the path that it took, counts of those, use those as proxies of difficulty. 

I think this covers everything in the decision making process and each step of the process can be automated eventually (post doc anyone?!). More importantly, it reflects ecological phenomonologcial experience of taking melodic dictaiton. 



--------------------------------------------------------- 

Aligns with intuitions that 
People who know more melodies will be better (singer phenomena) 
People will try for bigger chunks first, then go to smaller ones
Atomistic transcription can happen but is inefficient 
People with higher chunking ability will do better
IC is helpful proxy for this in line with IDyOM literature 
Relative pitch is where it’s at for things like this

Having now gone through the model verbally and notating the parameters that need to be set and how things are then represented, I will now define the model formally. 

## MoDiMe 

* Formal Model here



## Example

Having now both described the model and defined it formally, I now can run through a brief example of how the model might work in practice by showing a melody to be dictated, a the corpus of melodies that it represents, and three iterations of model that exhaust each branch of the model.

### Example Corpus

* 12 Melodies on on page and their representation 
* Also show rhythmic and pitch abstractions
* Show their density histograms as a corpus 


* Target Melody

* Define WMC low for example
* Linear re-entry 

* First run through take n- gram chunk, no explicit pattern match, drop 1 gram, yes match, move on
* Next no exact pattern match on linear re-entry, query pitch (yes, proto) query rhythm (yes,rhythm), both transcribed
* Third iteration, full pattern match
* Not complete, but at this point have X amount of melody transcribed with this history.
* Tedious to get the exact thing, go to actual example

* CRAZY THAT YOU COULD USE THIS TO WORK BACKWARDS HOLY SHIT BAYES YOU ARE SWEET!! 

### Actual Data

* Let's now say that we have set of XYZ melodies as targets, the whole semester 1's melodies the prior knowledge, what does the model then say.
* This basically mirrors week 1 of semester 2 of freshman year
* Plot of correlation of model predicts, correlation of actual scores
* Can re-do this now with only pitch scores (or run it with just pitch!)
* Can re-do this now with only rhythm score 

And here is some commentary 


## Future Directions

Now with a formal model of melodic dictation, what is now possible?

* Importantly have formal model of what might be phenomeonlogilly way people do melodic dictation.


* Talk explicitly about representation
* Talk about what happens when
* Link to sight singing
* Testable hypotheses?
* What's the deal with AP 
* Problems with how to define prior
* Future Directions
* How this all relates to helping teach 
* aka explain the model, thus explain learning, perception, process, representation, if one rep performs better than another, atomistic singing 

-------------------------------

## Advantages Of A Computational Model (Optional)

It is important to note that this model is not perfect in that it deterministically mirrors the exact cognitive process someone would use to take melodic dictation.
It instead quantifies each step of the process and provides a detailed account each step in a fully realized and implementable model.
The benefits of creating a computational model of melodic dictation are numerous.
First, as stated above, a computational model acts as an explanatory model that details the inner working of a process.
Second, by quantifying each step of the process, a computational model forces the researcher to specify key theoretical issues that need to be addressed and operationalized.
In this case, there is the issue of representation of musical material, definitions of working memory, as well as what does it mean for something to have been learned. 
Thirdly, in creating a computational model you provide theories with a concrete version that can be more easier falsified.
^[The quintessential example of the importance of this comes from an anecdote in evolutionary psychology claiming that in heterosexual populations, men engage in more casual sexual encounters than women due to their promiscuous proclivities.
This theory has appeared in textbooks, but as noted by AUTHOR, while might be good as a verbal model in that it plays to our preconceived notions about male sexuality, implemented as a computational model, is mathematically impossible.]
Fourthly, creating a computational model rules defines the universe of a possible outcomes that a theory posits.
As shown in work done on the seemingly simple Baddeley and Hitch model of working memory, AUTHOR demonstrated that with XXX parameter values, the YEAR model of working memory actually allows for 15X different permutations of the model.
With such vast possibilities, it becomes much harder to speak about _the_ model as a single entity.
Finally, and most importantly from a pedagogical framework, by detailing the exact steps of the process, a computational model provides a theory of melodic dictation in which each element of the process is able to be discussed and gives exact framework for which it can be critiqued.
Creating a computational model is the next step in furthering research on aural skills pedagogy.

 


Much work has been done on this history of musical representation WIGGINS ET AL 1993 has been exhaustive, even though it has only been on for about 30 years but regardless of what exact representation is chosen, it generally can be conceived of as some sort of symbol string Clifford et al., 2005.
How a string is represented carries with it important assumptions about a listener's perception and also a teacher's pedagogy.
Take for example the many ways in which someone could represent the ever popular Twinkle, Twinkle Little Star as in Figure 1. 

* TWINNLE IMAGE HERE in C and F#

Representing the string of symbols as in Figure 2A using THIS NOTATION SYSTEM would suggest that listeners perception and cognition of the notes mirrors that of fixed _do_ solfege.
The only symbols in the string, or tokens, represented carry with it the name of the note along with its absolute range.
When compared to string 2B-- the melody transposed a tritone up-- a computer would find no symbol overlap between the two strings and might declare the two as completely dissimilar.
Additionally, neither string contains with it any rhythmic information.
Reproduced Figure 2C and Figure 2D, we see the same two strings now with additionally temporal information.

* FIGURE 2 DIFFERENT TYPES OF REPRESENTATION
* C4 C4 G4 G4 A4 A4 G4
* F#4 F#4 C#5 C#5 D#6 D#6 C#6

As stated above, this mapping assumes fixed pitch representation of musical information.
This is at odds to intuition in that most humans would categorize the information in strings 2A and 2B as containing the same musical content.

In order to capture that aspect of human perception and cognition, one might want to represent this string of musical information to the computer as a list of directional intervals (Math citation) which brings with it interval information not present (although maybe implicitly imposed!) in the previous examples.

* C U +P5 U +M2 U -M2

This representation then captures what might be considered phenomena closer to human perception, but again is devoid of any sort of scale degree functionality or qualia that might be involved in listener's perception.
Including this assumption the string and duration values as it might be a Humdrum spine might be represented as:

* DO DO ^SOL SOL ^LA LA >SOL (with rhythm)

Each string represents what might be considered the same perceptual phenomena, but when quantified, one system needs to be explicitly chosen as how information is represented will change model output.
For example if it is assumed that an individual's prior musical information can only be encoded as the first _fixed do_ example, then each of the 12 possible ascending perfect fifths would have to be learned as separate phenomena to be represented in as prior knowledge in this model.
This point also brings up the importance of noting that many of these systems could be at play here and just because one representation might not make sense in one implementation of a model does not make it null and void for other applications in pedagogical settings.

Given what was stated above, there are many was in which to digitally represent musical information.
That said, one advantage in using the pre-exisiting IDyOM model as the backbone for this model is that it is capable of representing many types of musical representation simultaneously.
Not only is pitch information represented, but using different WINDOWS, it then becomes possible to encode these multitude of parameter simultaneously (LIST THEM HERE?) each as their own token, which then can be used to model information content. 

